{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import NCFDataset\n",
    "from recom_ncf import NCFRecommender\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "app_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "voted_up",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "timestamp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6702cdf6-fe1c-410b-8203-3bdd98c692b9",
       "rows": [
        [
         "0",
         "76561197960432447",
         "10",
         "True",
         "1738278781",
         "A legendary tactical shooter that shaped the genre. Simple yet deep gameplay, excellent weapon balance, and iconic maps keep the game relevant even today. Pure nostalgia and classic FPS action."
        ],
        [
         "1",
         "76561198071230926",
         "10",
         "True",
         "1736206418",
         "The best CS sure, but server browser is the illusion of choice and leads you to the same **** server. Use gametracker or something"
        ],
        [
         "2",
         "76561198206216352",
         "10",
         "True",
         "1738041574",
         "Some of the best memories of my childhood were made in pixels, with friends I only knew through a screen. Time moves on, but those moments are forever frozen in time."
        ],
        [
         "3",
         "76561198110801124",
         "10",
         "True",
         "1738015332",
         "This game feels so much better than CS2. I know this game still gets FACEIT/ESEA-type treatment from services in the EU, but it would be cool if it got such services in NA."
        ],
        [
         "4",
         "76561199813732773",
         "10",
         "True",
         "1737853720",
         "its very fun to play you can make friends out of it i have lots of maps i like i like how theres diffrent teams to choose from idk what else to say its just fun"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960432447</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1738278781</td>\n",
       "      <td>A legendary tactical shooter that shaped the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561198071230926</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1736206418</td>\n",
       "      <td>The best CS sure, but server browser is the il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198206216352</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1738041574</td>\n",
       "      <td>Some of the best memories of my childhood were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198110801124</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1738015332</td>\n",
       "      <td>This game feels so much better than CS2. I kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561199813732773</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1737853720</td>\n",
       "      <td>its very fun to play you can make friends out ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author_id  app_id  voted_up   timestamp  \\\n",
       "0  76561197960432447      10      True  1738278781   \n",
       "1  76561198071230926      10      True  1736206418   \n",
       "2  76561198206216352      10      True  1738041574   \n",
       "3  76561198110801124      10      True  1738015332   \n",
       "4  76561199813732773      10      True  1737853720   \n",
       "\n",
       "                                              review  \n",
       "0  A legendary tactical shooter that shaped the g...  \n",
       "1  The best CS sure, but server browser is the il...  \n",
       "2  Some of the best memories of my childhood were...  \n",
       "3  This game feels so much better than CS2. I kno...  \n",
       "4  its very fun to play you can make friends out ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/review-raw.csv')[['author_id', 'app_id', 'voted_up', 'timestamp', 'review']].copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping user id and app id to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_map = {u: i for i, u in enumerate(df['author_id'].unique())}\n",
    "item_map = {i: j for j, i in enumerate(df['app_id'].unique())}\n",
    "\n",
    "df['user_idx'] = np.array([user_map[u] for u in df['author_id']])\n",
    "df['item_idx'] = np.array([item_map[i] for i in df['app_id']])\n",
    "df['rating_int'] = df['voted_up'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_eval, df_test = train_test_split(df[['user_idx', 'item_idx', 'rating_int']], test_size=0.1, random_state=42)\n",
    "df_train, df_eval = train_test_split(df_train_eval, test_size=(0.1/0.9), random_state=42)\n",
    "\n",
    "train_dataset = NCFDataset(df_train)\n",
    "eval_dataset = NCFDataset(df_eval)\n",
    "test_dataset = NCFDataset(df_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=256, shuffle=False)\n",
    "test_dataloader = DataLoader(eval_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "unique_users = df[\"user_idx\"].unique()\n",
    "unique_items = df[\"item_idx\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1413153, 3)\n",
      "(176645, 3)\n",
      "(176645, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_eval.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.768205  [  256/1413153]\n",
      "loss: 0.747881  [25856/1413153]\n",
      "loss: 0.729712  [51456/1413153]\n",
      "loss: 0.757479  [77056/1413153]\n",
      "loss: 0.734396  [102656/1413153]\n",
      "loss: 0.697407  [128256/1413153]\n",
      "loss: 0.693570  [153856/1413153]\n",
      "loss: 0.660424  [179456/1413153]\n",
      "loss: 0.690643  [205056/1413153]\n",
      "loss: 0.660340  [230656/1413153]\n",
      "loss: 0.634344  [256256/1413153]\n",
      "loss: 0.628638  [281856/1413153]\n",
      "loss: 0.642558  [307456/1413153]\n",
      "loss: 0.636001  [333056/1413153]\n",
      "loss: 0.637851  [358656/1413153]\n",
      "loss: 0.594645  [384256/1413153]\n",
      "loss: 0.598754  [409856/1413153]\n",
      "loss: 0.576477  [435456/1413153]\n",
      "loss: 0.574407  [461056/1413153]\n",
      "loss: 0.589863  [486656/1413153]\n",
      "loss: 0.557897  [512256/1413153]\n",
      "loss: 0.558176  [537856/1413153]\n",
      "loss: 0.552395  [563456/1413153]\n",
      "loss: 0.554169  [589056/1413153]\n",
      "loss: 0.535275  [614656/1413153]\n",
      "loss: 0.560924  [640256/1413153]\n",
      "loss: 0.558120  [665856/1413153]\n",
      "loss: 0.562245  [691456/1413153]\n",
      "loss: 0.515280  [717056/1413153]\n",
      "loss: 0.570593  [742656/1413153]\n",
      "loss: 0.516623  [768256/1413153]\n",
      "loss: 0.564284  [793856/1413153]\n",
      "loss: 0.517991  [819456/1413153]\n",
      "loss: 0.495208  [845056/1413153]\n",
      "loss: 0.503788  [870656/1413153]\n",
      "loss: 0.482395  [896256/1413153]\n",
      "loss: 0.517439  [921856/1413153]\n",
      "loss: 0.490018  [947456/1413153]\n",
      "loss: 0.485114  [973056/1413153]\n",
      "loss: 0.505316  [998656/1413153]\n",
      "loss: 0.551464  [1024256/1413153]\n",
      "loss: 0.480853  [1049856/1413153]\n",
      "loss: 0.506978  [1075456/1413153]\n",
      "loss: 0.493380  [1101056/1413153]\n",
      "loss: 0.488673  [1126656/1413153]\n",
      "loss: 0.497900  [1152256/1413153]\n",
      "loss: 0.462997  [1177856/1413153]\n",
      "loss: 0.492206  [1203456/1413153]\n",
      "loss: 0.565395  [1229056/1413153]\n",
      "loss: 0.459011  [1254656/1413153]\n",
      "loss: 0.497086  [1280256/1413153]\n",
      "loss: 0.446076  [1305856/1413153]\n",
      "loss: 0.483080  [1331456/1413153]\n",
      "loss: 0.497310  [1357056/1413153]\n",
      "loss: 0.428499  [1382656/1413153]\n",
      "loss: 0.482206  [1408256/1413153]\n",
      "Avg loss on test: 0.477436 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.477232  [  256/1413153]\n",
      "loss: 0.474563  [25856/1413153]\n",
      "loss: 0.469326  [51456/1413153]\n",
      "loss: 0.484081  [77056/1413153]\n",
      "loss: 0.487446  [102656/1413153]\n",
      "loss: 0.442572  [128256/1413153]\n",
      "loss: 0.471184  [153856/1413153]\n",
      "loss: 0.416950  [179456/1413153]\n",
      "loss: 0.440939  [205056/1413153]\n",
      "loss: 0.483679  [230656/1413153]\n",
      "loss: 0.480854  [256256/1413153]\n",
      "loss: 0.493431  [281856/1413153]\n",
      "loss: 0.501599  [307456/1413153]\n",
      "loss: 0.503488  [333056/1413153]\n",
      "loss: 0.530445  [358656/1413153]\n",
      "loss: 0.453771  [384256/1413153]\n",
      "loss: 0.454966  [409856/1413153]\n",
      "loss: 0.472849  [435456/1413153]\n",
      "loss: 0.467232  [461056/1413153]\n",
      "loss: 0.498272  [486656/1413153]\n",
      "loss: 0.433500  [512256/1413153]\n",
      "loss: 0.467526  [537856/1413153]\n",
      "loss: 0.455118  [563456/1413153]\n",
      "loss: 0.504832  [589056/1413153]\n",
      "loss: 0.497490  [614656/1413153]\n",
      "loss: 0.447307  [640256/1413153]\n",
      "loss: 0.491500  [665856/1413153]\n",
      "loss: 0.521624  [691456/1413153]\n",
      "loss: 0.494003  [717056/1413153]\n",
      "loss: 0.458543  [742656/1413153]\n",
      "loss: 0.478407  [768256/1413153]\n",
      "loss: 0.520149  [793856/1413153]\n",
      "loss: 0.531357  [819456/1413153]\n",
      "loss: 0.467699  [845056/1413153]\n",
      "loss: 0.484478  [870656/1413153]\n",
      "loss: 0.459599  [896256/1413153]\n",
      "loss: 0.441776  [921856/1413153]\n",
      "loss: 0.479959  [947456/1413153]\n",
      "loss: 0.475600  [973056/1413153]\n",
      "loss: 0.502417  [998656/1413153]\n",
      "loss: 0.407839  [1024256/1413153]\n",
      "loss: 0.442923  [1049856/1413153]\n",
      "loss: 0.461671  [1075456/1413153]\n",
      "loss: 0.443480  [1101056/1413153]\n",
      "loss: 0.444658  [1126656/1413153]\n",
      "loss: 0.471001  [1152256/1413153]\n",
      "loss: 0.439640  [1177856/1413153]\n",
      "loss: 0.499516  [1203456/1413153]\n",
      "loss: 0.452310  [1229056/1413153]\n",
      "loss: 0.449262  [1254656/1413153]\n",
      "loss: 0.523484  [1280256/1413153]\n",
      "loss: 0.469525  [1305856/1413153]\n",
      "loss: 0.528549  [1331456/1413153]\n",
      "loss: 0.526983  [1357056/1413153]\n",
      "loss: 0.525227  [1382656/1413153]\n",
      "loss: 0.464621  [1408256/1413153]\n",
      "Avg loss on test: 0.467411 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.429720  [  256/1413153]\n",
      "loss: 0.438759  [25856/1413153]\n",
      "loss: 0.433225  [51456/1413153]\n",
      "loss: 0.485208  [77056/1413153]\n",
      "loss: 0.447457  [102656/1413153]\n",
      "loss: 0.486701  [128256/1413153]\n",
      "loss: 0.506695  [153856/1413153]\n",
      "loss: 0.484785  [179456/1413153]\n",
      "loss: 0.455118  [205056/1413153]\n",
      "loss: 0.451522  [230656/1413153]\n",
      "loss: 0.421139  [256256/1413153]\n",
      "loss: 0.464964  [281856/1413153]\n",
      "loss: 0.545494  [307456/1413153]\n",
      "loss: 0.502840  [333056/1413153]\n",
      "loss: 0.407172  [358656/1413153]\n",
      "loss: 0.495877  [384256/1413153]\n",
      "loss: 0.464125  [409856/1413153]\n",
      "loss: 0.477635  [435456/1413153]\n",
      "loss: 0.516853  [461056/1413153]\n",
      "loss: 0.426218  [486656/1413153]\n",
      "loss: 0.525775  [512256/1413153]\n",
      "loss: 0.411291  [537856/1413153]\n",
      "loss: 0.544737  [563456/1413153]\n",
      "loss: 0.447005  [589056/1413153]\n",
      "loss: 0.440638  [614656/1413153]\n",
      "loss: 0.450934  [640256/1413153]\n",
      "loss: 0.446287  [665856/1413153]\n",
      "loss: 0.486760  [691456/1413153]\n",
      "loss: 0.522362  [717056/1413153]\n",
      "loss: 0.508108  [742656/1413153]\n",
      "loss: 0.389973  [768256/1413153]\n",
      "loss: 0.485226  [793856/1413153]\n",
      "loss: 0.475908  [819456/1413153]\n",
      "loss: 0.485895  [845056/1413153]\n",
      "loss: 0.452435  [870656/1413153]\n",
      "loss: 0.541588  [896256/1413153]\n",
      "loss: 0.524029  [921856/1413153]\n",
      "loss: 0.470494  [947456/1413153]\n",
      "loss: 0.431313  [973056/1413153]\n",
      "loss: 0.517268  [998656/1413153]\n",
      "loss: 0.477782  [1024256/1413153]\n",
      "loss: 0.527148  [1049856/1413153]\n",
      "loss: 0.473827  [1075456/1413153]\n",
      "loss: 0.470064  [1101056/1413153]\n",
      "loss: 0.352128  [1126656/1413153]\n",
      "loss: 0.418160  [1152256/1413153]\n",
      "loss: 0.500566  [1177856/1413153]\n",
      "loss: 0.422112  [1203456/1413153]\n",
      "loss: 0.537096  [1229056/1413153]\n",
      "loss: 0.507386  [1254656/1413153]\n",
      "loss: 0.461355  [1280256/1413153]\n",
      "loss: 0.511988  [1305856/1413153]\n",
      "loss: 0.518286  [1331456/1413153]\n",
      "loss: 0.460773  [1357056/1413153]\n",
      "loss: 0.475827  [1382656/1413153]\n",
      "loss: 0.436719  [1408256/1413153]\n",
      "Avg loss on test: 0.466846 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.495636  [  256/1413153]\n",
      "loss: 0.555927  [25856/1413153]\n",
      "loss: 0.443176  [51456/1413153]\n",
      "loss: 0.542178  [77056/1413153]\n",
      "loss: 0.412446  [102656/1413153]\n",
      "loss: 0.483877  [128256/1413153]\n",
      "loss: 0.422998  [153856/1413153]\n",
      "loss: 0.465159  [179456/1413153]\n",
      "loss: 0.463783  [205056/1413153]\n",
      "loss: 0.482386  [230656/1413153]\n",
      "loss: 0.457652  [256256/1413153]\n",
      "loss: 0.489927  [281856/1413153]\n",
      "loss: 0.538206  [307456/1413153]\n",
      "loss: 0.552844  [333056/1413153]\n",
      "loss: 0.512876  [358656/1413153]\n",
      "loss: 0.497774  [384256/1413153]\n",
      "loss: 0.484029  [409856/1413153]\n",
      "loss: 0.519572  [435456/1413153]\n",
      "loss: 0.469943  [461056/1413153]\n",
      "loss: 0.499751  [486656/1413153]\n",
      "loss: 0.550765  [512256/1413153]\n",
      "loss: 0.479039  [537856/1413153]\n",
      "loss: 0.469776  [563456/1413153]\n",
      "loss: 0.424527  [589056/1413153]\n",
      "loss: 0.494789  [614656/1413153]\n",
      "loss: 0.495301  [640256/1413153]\n",
      "loss: 0.483233  [665856/1413153]\n",
      "loss: 0.474867  [691456/1413153]\n",
      "loss: 0.489899  [717056/1413153]\n",
      "loss: 0.468392  [742656/1413153]\n",
      "loss: 0.495545  [768256/1413153]\n",
      "loss: 0.464355  [793856/1413153]\n",
      "loss: 0.503677  [819456/1413153]\n",
      "loss: 0.507969  [845056/1413153]\n",
      "loss: 0.502609  [870656/1413153]\n",
      "loss: 0.440339  [896256/1413153]\n",
      "loss: 0.482752  [921856/1413153]\n",
      "loss: 0.519375  [947456/1413153]\n",
      "loss: 0.425149  [973056/1413153]\n",
      "loss: 0.508017  [998656/1413153]\n",
      "loss: 0.462009  [1024256/1413153]\n",
      "loss: 0.472343  [1049856/1413153]\n",
      "loss: 0.478649  [1075456/1413153]\n",
      "loss: 0.461389  [1101056/1413153]\n",
      "loss: 0.435590  [1126656/1413153]\n",
      "loss: 0.458591  [1152256/1413153]\n",
      "loss: 0.465608  [1177856/1413153]\n",
      "loss: 0.474781  [1203456/1413153]\n",
      "loss: 0.501143  [1229056/1413153]\n",
      "loss: 0.470586  [1254656/1413153]\n",
      "loss: 0.524259  [1280256/1413153]\n",
      "loss: 0.435996  [1305856/1413153]\n",
      "loss: 0.467694  [1331456/1413153]\n",
      "loss: 0.456781  [1357056/1413153]\n",
      "loss: 0.477203  [1382656/1413153]\n",
      "loss: 0.532549  [1408256/1413153]\n",
      "Avg loss on test: 0.466635 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.429349  [  256/1413153]\n",
      "loss: 0.523551  [25856/1413153]\n",
      "loss: 0.514166  [51456/1413153]\n",
      "loss: 0.560827  [77056/1413153]\n",
      "loss: 0.481368  [102656/1413153]\n",
      "loss: 0.499144  [128256/1413153]\n",
      "loss: 0.463546  [153856/1413153]\n",
      "loss: 0.479286  [179456/1413153]\n",
      "loss: 0.520474  [205056/1413153]\n",
      "loss: 0.477804  [230656/1413153]\n",
      "loss: 0.444563  [256256/1413153]\n",
      "loss: 0.498376  [281856/1413153]\n",
      "loss: 0.488071  [307456/1413153]\n",
      "loss: 0.451570  [333056/1413153]\n",
      "loss: 0.461609  [358656/1413153]\n",
      "loss: 0.413303  [384256/1413153]\n",
      "loss: 0.469731  [409856/1413153]\n",
      "loss: 0.457548  [435456/1413153]\n",
      "loss: 0.441594  [461056/1413153]\n",
      "loss: 0.481475  [486656/1413153]\n",
      "loss: 0.499894  [512256/1413153]\n",
      "loss: 0.432564  [537856/1413153]\n",
      "loss: 0.469285  [563456/1413153]\n",
      "loss: 0.468385  [589056/1413153]\n",
      "loss: 0.456391  [614656/1413153]\n",
      "loss: 0.443595  [640256/1413153]\n",
      "loss: 0.460689  [665856/1413153]\n",
      "loss: 0.498168  [691456/1413153]\n",
      "loss: 0.504270  [717056/1413153]\n",
      "loss: 0.514537  [742656/1413153]\n",
      "loss: 0.457830  [768256/1413153]\n",
      "loss: 0.488061  [793856/1413153]\n",
      "loss: 0.407761  [819456/1413153]\n",
      "loss: 0.428329  [845056/1413153]\n",
      "loss: 0.484191  [870656/1413153]\n",
      "loss: 0.548332  [896256/1413153]\n",
      "loss: 0.471603  [921856/1413153]\n",
      "loss: 0.383204  [947456/1413153]\n",
      "loss: 0.475793  [973056/1413153]\n",
      "loss: 0.524384  [998656/1413153]\n",
      "loss: 0.462624  [1024256/1413153]\n",
      "loss: 0.524759  [1049856/1413153]\n",
      "loss: 0.450909  [1075456/1413153]\n",
      "loss: 0.411884  [1101056/1413153]\n",
      "loss: 0.465746  [1126656/1413153]\n",
      "loss: 0.415331  [1152256/1413153]\n",
      "loss: 0.482862  [1177856/1413153]\n",
      "loss: 0.427496  [1203456/1413153]\n",
      "loss: 0.470976  [1229056/1413153]\n",
      "loss: 0.494670  [1254656/1413153]\n",
      "loss: 0.447657  [1280256/1413153]\n",
      "loss: 0.454304  [1305856/1413153]\n",
      "loss: 0.452843  [1331456/1413153]\n",
      "loss: 0.439811  [1357056/1413153]\n",
      "loss: 0.429434  [1382656/1413153]\n",
      "loss: 0.478345  [1408256/1413153]\n",
      "Avg loss on test: 0.466500 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.428953  [  256/1413153]\n",
      "loss: 0.480594  [25856/1413153]\n",
      "loss: 0.526576  [51456/1413153]\n",
      "loss: 0.435301  [77056/1413153]\n",
      "loss: 0.471140  [102656/1413153]\n",
      "loss: 0.484179  [128256/1413153]\n",
      "loss: 0.458465  [153856/1413153]\n",
      "loss: 0.422065  [179456/1413153]\n",
      "loss: 0.477708  [205056/1413153]\n",
      "loss: 0.502796  [230656/1413153]\n",
      "loss: 0.470358  [256256/1413153]\n",
      "loss: 0.494422  [281856/1413153]\n",
      "loss: 0.495627  [307456/1413153]\n",
      "loss: 0.494731  [333056/1413153]\n",
      "loss: 0.526895  [358656/1413153]\n",
      "loss: 0.463749  [384256/1413153]\n",
      "loss: 0.473195  [409856/1413153]\n",
      "loss: 0.502944  [435456/1413153]\n",
      "loss: 0.415870  [461056/1413153]\n",
      "loss: 0.429346  [486656/1413153]\n",
      "loss: 0.498902  [512256/1413153]\n",
      "loss: 0.489852  [537856/1413153]\n",
      "loss: 0.461152  [563456/1413153]\n",
      "loss: 0.555648  [589056/1413153]\n",
      "loss: 0.458784  [614656/1413153]\n",
      "loss: 0.434666  [640256/1413153]\n",
      "loss: 0.464996  [665856/1413153]\n",
      "loss: 0.491731  [691456/1413153]\n",
      "loss: 0.458779  [717056/1413153]\n",
      "loss: 0.436227  [742656/1413153]\n",
      "loss: 0.516567  [768256/1413153]\n",
      "loss: 0.438010  [793856/1413153]\n",
      "loss: 0.488446  [819456/1413153]\n",
      "loss: 0.423206  [845056/1413153]\n",
      "loss: 0.524607  [870656/1413153]\n",
      "loss: 0.478600  [896256/1413153]\n",
      "loss: 0.477683  [921856/1413153]\n",
      "loss: 0.495667  [947456/1413153]\n",
      "loss: 0.496743  [973056/1413153]\n",
      "loss: 0.438344  [998656/1413153]\n",
      "loss: 0.467779  [1024256/1413153]\n",
      "loss: 0.472240  [1049856/1413153]\n",
      "loss: 0.470137  [1075456/1413153]\n",
      "loss: 0.454066  [1101056/1413153]\n",
      "loss: 0.443523  [1126656/1413153]\n",
      "loss: 0.485793  [1152256/1413153]\n",
      "loss: 0.537450  [1177856/1413153]\n",
      "loss: 0.458767  [1203456/1413153]\n",
      "loss: 0.520975  [1229056/1413153]\n",
      "loss: 0.466859  [1254656/1413153]\n",
      "loss: 0.434469  [1280256/1413153]\n",
      "loss: 0.526980  [1305856/1413153]\n",
      "loss: 0.472854  [1331456/1413153]\n",
      "loss: 0.431746  [1357056/1413153]\n",
      "loss: 0.418878  [1382656/1413153]\n",
      "loss: 0.478309  [1408256/1413153]\n",
      "Avg loss on test: 0.466387 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.472075  [  256/1413153]\n",
      "loss: 0.435060  [25856/1413153]\n",
      "loss: 0.476003  [51456/1413153]\n",
      "loss: 0.459765  [77056/1413153]\n",
      "loss: 0.435734  [102656/1413153]\n",
      "loss: 0.442062  [128256/1413153]\n",
      "loss: 0.478727  [153856/1413153]\n",
      "loss: 0.499607  [179456/1413153]\n",
      "loss: 0.488784  [205056/1413153]\n",
      "loss: 0.470681  [230656/1413153]\n",
      "loss: 0.571747  [256256/1413153]\n",
      "loss: 0.458218  [281856/1413153]\n",
      "loss: 0.562301  [307456/1413153]\n",
      "loss: 0.445177  [333056/1413153]\n",
      "loss: 0.461374  [358656/1413153]\n",
      "loss: 0.436158  [384256/1413153]\n",
      "loss: 0.471258  [409856/1413153]\n",
      "loss: 0.448262  [435456/1413153]\n",
      "loss: 0.480753  [461056/1413153]\n",
      "loss: 0.493707  [486656/1413153]\n",
      "loss: 0.433788  [512256/1413153]\n",
      "loss: 0.447377  [537856/1413153]\n",
      "loss: 0.476798  [563456/1413153]\n",
      "loss: 0.481710  [589056/1413153]\n",
      "loss: 0.430586  [614656/1413153]\n",
      "loss: 0.508436  [640256/1413153]\n",
      "loss: 0.478515  [665856/1413153]\n",
      "loss: 0.451826  [691456/1413153]\n",
      "loss: 0.472527  [717056/1413153]\n",
      "loss: 0.417221  [742656/1413153]\n",
      "loss: 0.440728  [768256/1413153]\n",
      "loss: 0.405681  [793856/1413153]\n",
      "loss: 0.482663  [819456/1413153]\n",
      "loss: 0.477069  [845056/1413153]\n",
      "loss: 0.439636  [870656/1413153]\n",
      "loss: 0.410765  [896256/1413153]\n",
      "loss: 0.437905  [921856/1413153]\n",
      "loss: 0.471451  [947456/1413153]\n",
      "loss: 0.470102  [973056/1413153]\n",
      "loss: 0.541905  [998656/1413153]\n",
      "loss: 0.461599  [1024256/1413153]\n",
      "loss: 0.537601  [1049856/1413153]\n",
      "loss: 0.477838  [1075456/1413153]\n",
      "loss: 0.518472  [1101056/1413153]\n",
      "loss: 0.481795  [1126656/1413153]\n",
      "loss: 0.422586  [1152256/1413153]\n",
      "loss: 0.503797  [1177856/1413153]\n",
      "loss: 0.405436  [1203456/1413153]\n",
      "loss: 0.422301  [1229056/1413153]\n",
      "loss: 0.410742  [1254656/1413153]\n",
      "loss: 0.451665  [1280256/1413153]\n",
      "loss: 0.518595  [1305856/1413153]\n",
      "loss: 0.465825  [1331456/1413153]\n",
      "loss: 0.429561  [1357056/1413153]\n",
      "loss: 0.501007  [1382656/1413153]\n",
      "loss: 0.442724  [1408256/1413153]\n",
      "Avg loss on test: 0.466294 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.482700  [  256/1413153]\n",
      "loss: 0.429371  [25856/1413153]\n",
      "loss: 0.547186  [51456/1413153]\n",
      "loss: 0.482835  [77056/1413153]\n",
      "loss: 0.404321  [102656/1413153]\n",
      "loss: 0.495905  [128256/1413153]\n",
      "loss: 0.475029  [153856/1413153]\n",
      "loss: 0.406535  [179456/1413153]\n",
      "loss: 0.453067  [205056/1413153]\n",
      "loss: 0.411035  [230656/1413153]\n",
      "loss: 0.398414  [256256/1413153]\n",
      "loss: 0.475114  [281856/1413153]\n",
      "loss: 0.493066  [307456/1413153]\n",
      "loss: 0.422593  [333056/1413153]\n",
      "loss: 0.427906  [358656/1413153]\n",
      "loss: 0.437222  [384256/1413153]\n",
      "loss: 0.474596  [409856/1413153]\n",
      "loss: 0.483095  [435456/1413153]\n",
      "loss: 0.531438  [461056/1413153]\n",
      "loss: 0.406373  [486656/1413153]\n",
      "loss: 0.487374  [512256/1413153]\n",
      "loss: 0.464355  [537856/1413153]\n",
      "loss: 0.430505  [563456/1413153]\n",
      "loss: 0.482093  [589056/1413153]\n",
      "loss: 0.433130  [614656/1413153]\n",
      "loss: 0.477058  [640256/1413153]\n",
      "loss: 0.470906  [665856/1413153]\n",
      "loss: 0.452528  [691456/1413153]\n",
      "loss: 0.458724  [717056/1413153]\n",
      "loss: 0.458989  [742656/1413153]\n",
      "loss: 0.453139  [768256/1413153]\n",
      "loss: 0.400200  [793856/1413153]\n",
      "loss: 0.521374  [819456/1413153]\n",
      "loss: 0.489803  [845056/1413153]\n",
      "loss: 0.453733  [870656/1413153]\n",
      "loss: 0.496632  [896256/1413153]\n",
      "loss: 0.560240  [921856/1413153]\n",
      "loss: 0.409844  [947456/1413153]\n",
      "loss: 0.415736  [973056/1413153]\n",
      "loss: 0.440620  [998656/1413153]\n",
      "loss: 0.459946  [1024256/1413153]\n",
      "loss: 0.489179  [1049856/1413153]\n",
      "loss: 0.454223  [1075456/1413153]\n",
      "loss: 0.488629  [1101056/1413153]\n",
      "loss: 0.493410  [1126656/1413153]\n",
      "loss: 0.467751  [1152256/1413153]\n",
      "loss: 0.471507  [1177856/1413153]\n",
      "loss: 0.467365  [1203456/1413153]\n",
      "loss: 0.446357  [1229056/1413153]\n",
      "loss: 0.472816  [1254656/1413153]\n",
      "loss: 0.469546  [1280256/1413153]\n",
      "loss: 0.510763  [1305856/1413153]\n",
      "loss: 0.470775  [1331456/1413153]\n",
      "loss: 0.511074  [1357056/1413153]\n",
      "loss: 0.495578  [1382656/1413153]\n",
      "loss: 0.470405  [1408256/1413153]\n",
      "Avg loss on test: 0.466197 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.462408  [  256/1413153]\n",
      "loss: 0.371919  [25856/1413153]\n",
      "loss: 0.501305  [51456/1413153]\n",
      "loss: 0.476011  [77056/1413153]\n",
      "loss: 0.502244  [102656/1413153]\n",
      "loss: 0.460337  [128256/1413153]\n",
      "loss: 0.501570  [153856/1413153]\n",
      "loss: 0.541937  [179456/1413153]\n",
      "loss: 0.492936  [205056/1413153]\n",
      "loss: 0.476691  [230656/1413153]\n",
      "loss: 0.471148  [256256/1413153]\n",
      "loss: 0.489353  [281856/1413153]\n",
      "loss: 0.482711  [307456/1413153]\n",
      "loss: 0.469010  [333056/1413153]\n",
      "loss: 0.444350  [358656/1413153]\n",
      "loss: 0.472191  [384256/1413153]\n",
      "loss: 0.422924  [409856/1413153]\n",
      "loss: 0.451367  [435456/1413153]\n",
      "loss: 0.495399  [461056/1413153]\n",
      "loss: 0.539993  [486656/1413153]\n",
      "loss: 0.483359  [512256/1413153]\n",
      "loss: 0.458171  [537856/1413153]\n",
      "loss: 0.471979  [563456/1413153]\n",
      "loss: 0.464624  [589056/1413153]\n",
      "loss: 0.466816  [614656/1413153]\n",
      "loss: 0.435780  [640256/1413153]\n",
      "loss: 0.497151  [665856/1413153]\n",
      "loss: 0.489584  [691456/1413153]\n",
      "loss: 0.520389  [717056/1413153]\n",
      "loss: 0.507986  [742656/1413153]\n",
      "loss: 0.505339  [768256/1413153]\n",
      "loss: 0.475364  [793856/1413153]\n",
      "loss: 0.447816  [819456/1413153]\n",
      "loss: 0.479694  [845056/1413153]\n",
      "loss: 0.471491  [870656/1413153]\n",
      "loss: 0.465972  [896256/1413153]\n",
      "loss: 0.427358  [921856/1413153]\n",
      "loss: 0.512380  [947456/1413153]\n",
      "loss: 0.447011  [973056/1413153]\n",
      "loss: 0.472096  [998656/1413153]\n",
      "loss: 0.533678  [1024256/1413153]\n",
      "loss: 0.483615  [1049856/1413153]\n",
      "loss: 0.494614  [1075456/1413153]\n",
      "loss: 0.418638  [1101056/1413153]\n",
      "loss: 0.467597  [1126656/1413153]\n",
      "loss: 0.466610  [1152256/1413153]\n",
      "loss: 0.446702  [1177856/1413153]\n",
      "loss: 0.458317  [1203456/1413153]\n",
      "loss: 0.445469  [1229056/1413153]\n",
      "loss: 0.465012  [1254656/1413153]\n",
      "loss: 0.427371  [1280256/1413153]\n",
      "loss: 0.503176  [1305856/1413153]\n",
      "loss: 0.510679  [1331456/1413153]\n",
      "loss: 0.464757  [1357056/1413153]\n",
      "loss: 0.431075  [1382656/1413153]\n",
      "loss: 0.497778  [1408256/1413153]\n",
      "Avg loss on test: 0.466112 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.453930  [  256/1413153]\n",
      "loss: 0.437280  [25856/1413153]\n",
      "loss: 0.464336  [51456/1413153]\n",
      "loss: 0.432380  [77056/1413153]\n",
      "loss: 0.450566  [102656/1413153]\n",
      "loss: 0.458510  [128256/1413153]\n",
      "loss: 0.517571  [153856/1413153]\n",
      "loss: 0.462418  [179456/1413153]\n",
      "loss: 0.480956  [205056/1413153]\n",
      "loss: 0.483037  [230656/1413153]\n",
      "loss: 0.485071  [256256/1413153]\n",
      "loss: 0.494694  [281856/1413153]\n",
      "loss: 0.436399  [307456/1413153]\n",
      "loss: 0.428846  [333056/1413153]\n",
      "loss: 0.519527  [358656/1413153]\n",
      "loss: 0.464322  [384256/1413153]\n",
      "loss: 0.490678  [409856/1413153]\n",
      "loss: 0.423646  [435456/1413153]\n",
      "loss: 0.481370  [461056/1413153]\n",
      "loss: 0.417412  [486656/1413153]\n",
      "loss: 0.423127  [512256/1413153]\n",
      "loss: 0.480927  [537856/1413153]\n",
      "loss: 0.470743  [563456/1413153]\n",
      "loss: 0.458689  [589056/1413153]\n",
      "loss: 0.457425  [614656/1413153]\n",
      "loss: 0.504968  [640256/1413153]\n",
      "loss: 0.483774  [665856/1413153]\n",
      "loss: 0.464043  [691456/1413153]\n",
      "loss: 0.498966  [717056/1413153]\n",
      "loss: 0.475119  [742656/1413153]\n",
      "loss: 0.427342  [768256/1413153]\n",
      "loss: 0.457681  [793856/1413153]\n",
      "loss: 0.409186  [819456/1413153]\n",
      "loss: 0.491566  [845056/1413153]\n",
      "loss: 0.460641  [870656/1413153]\n",
      "loss: 0.451539  [896256/1413153]\n",
      "loss: 0.470922  [921856/1413153]\n",
      "loss: 0.542853  [947456/1413153]\n",
      "loss: 0.375231  [973056/1413153]\n",
      "loss: 0.481494  [998656/1413153]\n",
      "loss: 0.534043  [1024256/1413153]\n",
      "loss: 0.500004  [1049856/1413153]\n",
      "loss: 0.435122  [1075456/1413153]\n",
      "loss: 0.483931  [1101056/1413153]\n",
      "loss: 0.431096  [1126656/1413153]\n",
      "loss: 0.416850  [1152256/1413153]\n",
      "loss: 0.505948  [1177856/1413153]\n",
      "loss: 0.487005  [1203456/1413153]\n",
      "loss: 0.522386  [1229056/1413153]\n",
      "loss: 0.447901  [1254656/1413153]\n",
      "loss: 0.402318  [1280256/1413153]\n",
      "loss: 0.476802  [1305856/1413153]\n",
      "loss: 0.509206  [1331456/1413153]\n",
      "loss: 0.413083  [1357056/1413153]\n",
      "loss: 0.478704  [1382656/1413153]\n",
      "loss: 0.427394  [1408256/1413153]\n",
      "Avg loss on test: 0.466044 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.484531  [  256/1413153]\n",
      "loss: 0.472445  [25856/1413153]\n",
      "loss: 0.472181  [51456/1413153]\n",
      "loss: 0.456097  [77056/1413153]\n",
      "loss: 0.482526  [102656/1413153]\n",
      "loss: 0.535924  [128256/1413153]\n",
      "loss: 0.448496  [153856/1413153]\n",
      "loss: 0.443642  [179456/1413153]\n",
      "loss: 0.462733  [205056/1413153]\n",
      "loss: 0.432885  [230656/1413153]\n",
      "loss: 0.436356  [256256/1413153]\n",
      "loss: 0.563414  [281856/1413153]\n",
      "loss: 0.513979  [307456/1413153]\n",
      "loss: 0.421895  [333056/1413153]\n",
      "loss: 0.516480  [358656/1413153]\n",
      "loss: 0.459168  [384256/1413153]\n",
      "loss: 0.546637  [409856/1413153]\n",
      "loss: 0.435623  [435456/1413153]\n",
      "loss: 0.400508  [461056/1413153]\n",
      "loss: 0.493527  [486656/1413153]\n",
      "loss: 0.482697  [512256/1413153]\n",
      "loss: 0.504948  [537856/1413153]\n",
      "loss: 0.465668  [563456/1413153]\n",
      "loss: 0.443323  [589056/1413153]\n",
      "loss: 0.512510  [614656/1413153]\n",
      "loss: 0.471860  [640256/1413153]\n",
      "loss: 0.520267  [665856/1413153]\n",
      "loss: 0.434915  [691456/1413153]\n",
      "loss: 0.445881  [717056/1413153]\n",
      "loss: 0.439861  [742656/1413153]\n",
      "loss: 0.378520  [768256/1413153]\n",
      "loss: 0.514922  [793856/1413153]\n",
      "loss: 0.448170  [819456/1413153]\n",
      "loss: 0.516267  [845056/1413153]\n",
      "loss: 0.498328  [870656/1413153]\n",
      "loss: 0.552911  [896256/1413153]\n",
      "loss: 0.512803  [921856/1413153]\n",
      "loss: 0.422526  [947456/1413153]\n",
      "loss: 0.515103  [973056/1413153]\n",
      "loss: 0.474655  [998656/1413153]\n",
      "loss: 0.480791  [1024256/1413153]\n",
      "loss: 0.446501  [1049856/1413153]\n",
      "loss: 0.471978  [1075456/1413153]\n",
      "loss: 0.435255  [1101056/1413153]\n",
      "loss: 0.536727  [1126656/1413153]\n",
      "loss: 0.445788  [1152256/1413153]\n",
      "loss: 0.448072  [1177856/1413153]\n",
      "loss: 0.499424  [1203456/1413153]\n",
      "loss: 0.400977  [1229056/1413153]\n",
      "loss: 0.472912  [1254656/1413153]\n",
      "loss: 0.504694  [1280256/1413153]\n",
      "loss: 0.459261  [1305856/1413153]\n",
      "loss: 0.453148  [1331456/1413153]\n",
      "loss: 0.458978  [1357056/1413153]\n",
      "loss: 0.445481  [1382656/1413153]\n",
      "loss: 0.439266  [1408256/1413153]\n",
      "Avg loss on test: 0.465970 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.447734  [  256/1413153]\n",
      "loss: 0.468424  [25856/1413153]\n",
      "loss: 0.451619  [51456/1413153]\n",
      "loss: 0.437954  [77056/1413153]\n",
      "loss: 0.486669  [102656/1413153]\n",
      "loss: 0.492202  [128256/1413153]\n",
      "loss: 0.437967  [153856/1413153]\n",
      "loss: 0.417425  [179456/1413153]\n",
      "loss: 0.499771  [205056/1413153]\n",
      "loss: 0.417843  [230656/1413153]\n",
      "loss: 0.398332  [256256/1413153]\n",
      "loss: 0.445128  [281856/1413153]\n",
      "loss: 0.430537  [307456/1413153]\n",
      "loss: 0.479682  [333056/1413153]\n",
      "loss: 0.435923  [358656/1413153]\n",
      "loss: 0.474658  [384256/1413153]\n",
      "loss: 0.427459  [409856/1413153]\n",
      "loss: 0.461690  [435456/1413153]\n",
      "loss: 0.422631  [461056/1413153]\n",
      "loss: 0.458106  [486656/1413153]\n",
      "loss: 0.454586  [512256/1413153]\n",
      "loss: 0.450954  [537856/1413153]\n",
      "loss: 0.487087  [563456/1413153]\n",
      "loss: 0.452397  [589056/1413153]\n",
      "loss: 0.514974  [614656/1413153]\n",
      "loss: 0.475929  [640256/1413153]\n",
      "loss: 0.490935  [665856/1413153]\n",
      "loss: 0.481725  [691456/1413153]\n",
      "loss: 0.511742  [717056/1413153]\n",
      "loss: 0.464334  [742656/1413153]\n",
      "loss: 0.516555  [768256/1413153]\n",
      "loss: 0.566666  [793856/1413153]\n",
      "loss: 0.500064  [819456/1413153]\n",
      "loss: 0.511831  [845056/1413153]\n",
      "loss: 0.416753  [870656/1413153]\n",
      "loss: 0.409484  [896256/1413153]\n",
      "loss: 0.494480  [921856/1413153]\n",
      "loss: 0.535221  [947456/1413153]\n",
      "loss: 0.530350  [973056/1413153]\n",
      "loss: 0.528598  [998656/1413153]\n",
      "loss: 0.501192  [1024256/1413153]\n",
      "loss: 0.510675  [1049856/1413153]\n",
      "loss: 0.442179  [1075456/1413153]\n",
      "loss: 0.530603  [1101056/1413153]\n",
      "loss: 0.477339  [1126656/1413153]\n",
      "loss: 0.462831  [1152256/1413153]\n",
      "loss: 0.525720  [1177856/1413153]\n",
      "loss: 0.442900  [1203456/1413153]\n",
      "loss: 0.480371  [1229056/1413153]\n",
      "loss: 0.528553  [1254656/1413153]\n",
      "loss: 0.525770  [1280256/1413153]\n",
      "loss: 0.533676  [1305856/1413153]\n",
      "loss: 0.522983  [1331456/1413153]\n",
      "loss: 0.449306  [1357056/1413153]\n",
      "loss: 0.547254  [1382656/1413153]\n",
      "loss: 0.470915  [1408256/1413153]\n",
      "Avg loss on test: 0.465904 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.487654  [  256/1413153]\n",
      "loss: 0.480477  [25856/1413153]\n",
      "loss: 0.509532  [51456/1413153]\n",
      "loss: 0.477743  [77056/1413153]\n",
      "loss: 0.492851  [102656/1413153]\n",
      "loss: 0.517575  [128256/1413153]\n",
      "loss: 0.523794  [153856/1413153]\n",
      "loss: 0.429787  [179456/1413153]\n",
      "loss: 0.470770  [205056/1413153]\n",
      "loss: 0.499370  [230656/1413153]\n",
      "loss: 0.467348  [256256/1413153]\n",
      "loss: 0.477473  [281856/1413153]\n",
      "loss: 0.436609  [307456/1413153]\n",
      "loss: 0.401902  [333056/1413153]\n",
      "loss: 0.415260  [358656/1413153]\n",
      "loss: 0.471529  [384256/1413153]\n",
      "loss: 0.507196  [409856/1413153]\n",
      "loss: 0.566746  [435456/1413153]\n",
      "loss: 0.486326  [461056/1413153]\n",
      "loss: 0.481701  [486656/1413153]\n",
      "loss: 0.452841  [512256/1413153]\n",
      "loss: 0.422626  [537856/1413153]\n",
      "loss: 0.517425  [563456/1413153]\n",
      "loss: 0.469178  [589056/1413153]\n",
      "loss: 0.486386  [614656/1413153]\n",
      "loss: 0.448823  [640256/1413153]\n",
      "loss: 0.459943  [665856/1413153]\n",
      "loss: 0.487378  [691456/1413153]\n",
      "loss: 0.507281  [717056/1413153]\n",
      "loss: 0.504096  [742656/1413153]\n",
      "loss: 0.472465  [768256/1413153]\n",
      "loss: 0.499988  [793856/1413153]\n",
      "loss: 0.412247  [819456/1413153]\n",
      "loss: 0.459115  [845056/1413153]\n",
      "loss: 0.416427  [870656/1413153]\n",
      "loss: 0.422053  [896256/1413153]\n",
      "loss: 0.504964  [921856/1413153]\n",
      "loss: 0.506329  [947456/1413153]\n",
      "loss: 0.503269  [973056/1413153]\n",
      "loss: 0.495073  [998656/1413153]\n",
      "loss: 0.370456  [1024256/1413153]\n",
      "loss: 0.488700  [1049856/1413153]\n",
      "loss: 0.490767  [1075456/1413153]\n",
      "loss: 0.503193  [1101056/1413153]\n",
      "loss: 0.530003  [1126656/1413153]\n",
      "loss: 0.421545  [1152256/1413153]\n",
      "loss: 0.489050  [1177856/1413153]\n",
      "loss: 0.412306  [1203456/1413153]\n",
      "loss: 0.446065  [1229056/1413153]\n",
      "loss: 0.499908  [1254656/1413153]\n",
      "loss: 0.441004  [1280256/1413153]\n",
      "loss: 0.428755  [1305856/1413153]\n",
      "loss: 0.513498  [1331456/1413153]\n",
      "loss: 0.469400  [1357056/1413153]\n",
      "loss: 0.503527  [1382656/1413153]\n",
      "loss: 0.471172  [1408256/1413153]\n",
      "Avg loss on test: 0.465835 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.463703  [  256/1413153]\n",
      "loss: 0.446725  [25856/1413153]\n",
      "loss: 0.497057  [51456/1413153]\n",
      "loss: 0.486562  [77056/1413153]\n",
      "loss: 0.500698  [102656/1413153]\n",
      "loss: 0.446511  [128256/1413153]\n",
      "loss: 0.525891  [153856/1413153]\n",
      "loss: 0.449135  [179456/1413153]\n",
      "loss: 0.510569  [205056/1413153]\n",
      "loss: 0.489454  [230656/1413153]\n",
      "loss: 0.469629  [256256/1413153]\n",
      "loss: 0.481602  [281856/1413153]\n",
      "loss: 0.401441  [307456/1413153]\n",
      "loss: 0.453719  [333056/1413153]\n",
      "loss: 0.495587  [358656/1413153]\n",
      "loss: 0.481404  [384256/1413153]\n",
      "loss: 0.424417  [409856/1413153]\n",
      "loss: 0.504314  [435456/1413153]\n",
      "loss: 0.548566  [461056/1413153]\n",
      "loss: 0.423345  [486656/1413153]\n",
      "loss: 0.400577  [512256/1413153]\n",
      "loss: 0.503581  [537856/1413153]\n",
      "loss: 0.445548  [563456/1413153]\n",
      "loss: 0.444045  [589056/1413153]\n",
      "loss: 0.500814  [614656/1413153]\n",
      "loss: 0.483502  [640256/1413153]\n",
      "loss: 0.451785  [665856/1413153]\n",
      "loss: 0.498327  [691456/1413153]\n",
      "loss: 0.472174  [717056/1413153]\n",
      "loss: 0.532907  [742656/1413153]\n",
      "loss: 0.505647  [768256/1413153]\n",
      "loss: 0.442254  [793856/1413153]\n",
      "loss: 0.471234  [819456/1413153]\n",
      "loss: 0.510423  [845056/1413153]\n",
      "loss: 0.507718  [870656/1413153]\n",
      "loss: 0.497776  [896256/1413153]\n",
      "loss: 0.499357  [921856/1413153]\n",
      "loss: 0.517632  [947456/1413153]\n",
      "loss: 0.434221  [973056/1413153]\n",
      "loss: 0.482618  [998656/1413153]\n",
      "loss: 0.440547  [1024256/1413153]\n",
      "loss: 0.441334  [1049856/1413153]\n",
      "loss: 0.449616  [1075456/1413153]\n",
      "loss: 0.416386  [1101056/1413153]\n",
      "loss: 0.489182  [1126656/1413153]\n",
      "loss: 0.422059  [1152256/1413153]\n",
      "loss: 0.423099  [1177856/1413153]\n",
      "loss: 0.431052  [1203456/1413153]\n",
      "loss: 0.455767  [1229056/1413153]\n",
      "loss: 0.472730  [1254656/1413153]\n",
      "loss: 0.447661  [1280256/1413153]\n",
      "loss: 0.490478  [1305856/1413153]\n",
      "loss: 0.463470  [1331456/1413153]\n",
      "loss: 0.476625  [1357056/1413153]\n",
      "loss: 0.460174  [1382656/1413153]\n",
      "loss: 0.494835  [1408256/1413153]\n",
      "Avg loss on test: 0.465766 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.454328  [  256/1413153]\n",
      "loss: 0.402094  [25856/1413153]\n",
      "loss: 0.464937  [51456/1413153]\n",
      "loss: 0.420957  [77056/1413153]\n",
      "loss: 0.436727  [102656/1413153]\n",
      "loss: 0.476578  [128256/1413153]\n",
      "loss: 0.427107  [153856/1413153]\n",
      "loss: 0.542228  [179456/1413153]\n",
      "loss: 0.484531  [205056/1413153]\n",
      "loss: 0.470820  [230656/1413153]\n",
      "loss: 0.499396  [256256/1413153]\n",
      "loss: 0.477823  [281856/1413153]\n",
      "loss: 0.385829  [307456/1413153]\n",
      "loss: 0.476685  [333056/1413153]\n",
      "loss: 0.489332  [358656/1413153]\n",
      "loss: 0.479445  [384256/1413153]\n",
      "loss: 0.489493  [409856/1413153]\n",
      "loss: 0.459750  [435456/1413153]\n",
      "loss: 0.405969  [461056/1413153]\n",
      "loss: 0.472036  [486656/1413153]\n",
      "loss: 0.479314  [512256/1413153]\n",
      "loss: 0.415338  [537856/1413153]\n",
      "loss: 0.512051  [563456/1413153]\n",
      "loss: 0.433090  [589056/1413153]\n",
      "loss: 0.535479  [614656/1413153]\n",
      "loss: 0.431836  [640256/1413153]\n",
      "loss: 0.487962  [665856/1413153]\n",
      "loss: 0.501353  [691456/1413153]\n",
      "loss: 0.434430  [717056/1413153]\n",
      "loss: 0.426120  [742656/1413153]\n",
      "loss: 0.484538  [768256/1413153]\n",
      "loss: 0.416140  [793856/1413153]\n",
      "loss: 0.472980  [819456/1413153]\n",
      "loss: 0.496741  [845056/1413153]\n",
      "loss: 0.401470  [870656/1413153]\n",
      "loss: 0.519050  [896256/1413153]\n",
      "loss: 0.468177  [921856/1413153]\n",
      "loss: 0.446299  [947456/1413153]\n",
      "loss: 0.532844  [973056/1413153]\n",
      "loss: 0.492142  [998656/1413153]\n",
      "loss: 0.452581  [1024256/1413153]\n",
      "loss: 0.421884  [1049856/1413153]\n",
      "loss: 0.453255  [1075456/1413153]\n",
      "loss: 0.454152  [1101056/1413153]\n",
      "loss: 0.428077  [1126656/1413153]\n",
      "loss: 0.442339  [1152256/1413153]\n",
      "loss: 0.469469  [1177856/1413153]\n",
      "loss: 0.456978  [1203456/1413153]\n",
      "loss: 0.470728  [1229056/1413153]\n",
      "loss: 0.457449  [1254656/1413153]\n",
      "loss: 0.433325  [1280256/1413153]\n",
      "loss: 0.559257  [1305856/1413153]\n",
      "loss: 0.434313  [1331456/1413153]\n",
      "loss: 0.436907  [1357056/1413153]\n",
      "loss: 0.441194  [1382656/1413153]\n",
      "loss: 0.418956  [1408256/1413153]\n",
      "Avg loss on test: 0.465700 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.433397  [  256/1413153]\n",
      "loss: 0.406244  [25856/1413153]\n",
      "loss: 0.495947  [51456/1413153]\n",
      "loss: 0.462881  [77056/1413153]\n",
      "loss: 0.521625  [102656/1413153]\n",
      "loss: 0.443921  [128256/1413153]\n",
      "loss: 0.487490  [153856/1413153]\n",
      "loss: 0.489816  [179456/1413153]\n",
      "loss: 0.478124  [205056/1413153]\n",
      "loss: 0.469417  [230656/1413153]\n",
      "loss: 0.512202  [256256/1413153]\n",
      "loss: 0.428922  [281856/1413153]\n",
      "loss: 0.401672  [307456/1413153]\n",
      "loss: 0.537221  [333056/1413153]\n",
      "loss: 0.496451  [358656/1413153]\n",
      "loss: 0.481817  [384256/1413153]\n",
      "loss: 0.457529  [409856/1413153]\n",
      "loss: 0.551606  [435456/1413153]\n",
      "loss: 0.452560  [461056/1413153]\n",
      "loss: 0.459852  [486656/1413153]\n",
      "loss: 0.455975  [512256/1413153]\n",
      "loss: 0.459750  [537856/1413153]\n",
      "loss: 0.405642  [563456/1413153]\n",
      "loss: 0.481762  [589056/1413153]\n",
      "loss: 0.423060  [614656/1413153]\n",
      "loss: 0.475802  [640256/1413153]\n",
      "loss: 0.411539  [665856/1413153]\n",
      "loss: 0.454711  [691456/1413153]\n",
      "loss: 0.451443  [717056/1413153]\n",
      "loss: 0.497912  [742656/1413153]\n",
      "loss: 0.444788  [768256/1413153]\n",
      "loss: 0.526009  [793856/1413153]\n",
      "loss: 0.500735  [819456/1413153]\n",
      "loss: 0.447502  [845056/1413153]\n",
      "loss: 0.470908  [870656/1413153]\n",
      "loss: 0.498021  [896256/1413153]\n",
      "loss: 0.442155  [921856/1413153]\n",
      "loss: 0.470930  [947456/1413153]\n",
      "loss: 0.417734  [973056/1413153]\n",
      "loss: 0.475376  [998656/1413153]\n",
      "loss: 0.471971  [1024256/1413153]\n",
      "loss: 0.446987  [1049856/1413153]\n",
      "loss: 0.469060  [1075456/1413153]\n",
      "loss: 0.496588  [1101056/1413153]\n",
      "loss: 0.488556  [1126656/1413153]\n",
      "loss: 0.426631  [1152256/1413153]\n",
      "loss: 0.483772  [1177856/1413153]\n",
      "loss: 0.480181  [1203456/1413153]\n",
      "loss: 0.548362  [1229056/1413153]\n",
      "loss: 0.386991  [1254656/1413153]\n",
      "loss: 0.473180  [1280256/1413153]\n",
      "loss: 0.410831  [1305856/1413153]\n",
      "loss: 0.470536  [1331456/1413153]\n",
      "loss: 0.541739  [1357056/1413153]\n",
      "loss: 0.463363  [1382656/1413153]\n",
      "loss: 0.487240  [1408256/1413153]\n",
      "Avg loss on test: 0.465647 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.462447  [  256/1413153]\n",
      "loss: 0.430438  [25856/1413153]\n",
      "loss: 0.492610  [51456/1413153]\n",
      "loss: 0.469152  [77056/1413153]\n",
      "loss: 0.458888  [102656/1413153]\n",
      "loss: 0.482278  [128256/1413153]\n",
      "loss: 0.481728  [153856/1413153]\n",
      "loss: 0.469223  [179456/1413153]\n",
      "loss: 0.474223  [205056/1413153]\n",
      "loss: 0.498102  [230656/1413153]\n",
      "loss: 0.482203  [256256/1413153]\n",
      "loss: 0.438261  [281856/1413153]\n",
      "loss: 0.461932  [307456/1413153]\n",
      "loss: 0.469041  [333056/1413153]\n",
      "loss: 0.485389  [358656/1413153]\n",
      "loss: 0.456403  [384256/1413153]\n",
      "loss: 0.433317  [409856/1413153]\n",
      "loss: 0.465241  [435456/1413153]\n",
      "loss: 0.439003  [461056/1413153]\n",
      "loss: 0.526663  [486656/1413153]\n",
      "loss: 0.443000  [512256/1413153]\n",
      "loss: 0.464982  [537856/1413153]\n",
      "loss: 0.470603  [563456/1413153]\n",
      "loss: 0.451925  [589056/1413153]\n",
      "loss: 0.507028  [614656/1413153]\n",
      "loss: 0.529568  [640256/1413153]\n",
      "loss: 0.408473  [665856/1413153]\n",
      "loss: 0.470246  [691456/1413153]\n",
      "loss: 0.428528  [717056/1413153]\n",
      "loss: 0.464469  [742656/1413153]\n",
      "loss: 0.444837  [768256/1413153]\n",
      "loss: 0.515805  [793856/1413153]\n",
      "loss: 0.492262  [819456/1413153]\n",
      "loss: 0.468253  [845056/1413153]\n",
      "loss: 0.548040  [870656/1413153]\n",
      "loss: 0.483176  [896256/1413153]\n",
      "loss: 0.464104  [921856/1413153]\n",
      "loss: 0.506884  [947456/1413153]\n",
      "loss: 0.457112  [973056/1413153]\n",
      "loss: 0.469407  [998656/1413153]\n",
      "loss: 0.481701  [1024256/1413153]\n",
      "loss: 0.416440  [1049856/1413153]\n",
      "loss: 0.397973  [1075456/1413153]\n",
      "loss: 0.430248  [1101056/1413153]\n",
      "loss: 0.479561  [1126656/1413153]\n",
      "loss: 0.490598  [1152256/1413153]\n",
      "loss: 0.509970  [1177856/1413153]\n",
      "loss: 0.435793  [1203456/1413153]\n",
      "loss: 0.416787  [1229056/1413153]\n",
      "loss: 0.493193  [1254656/1413153]\n",
      "loss: 0.453212  [1280256/1413153]\n",
      "loss: 0.481893  [1305856/1413153]\n",
      "loss: 0.442309  [1331456/1413153]\n",
      "loss: 0.472776  [1357056/1413153]\n",
      "loss: 0.483154  [1382656/1413153]\n",
      "loss: 0.464999  [1408256/1413153]\n",
      "Avg loss on test: 0.465593 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.470626  [  256/1413153]\n",
      "loss: 0.529425  [25856/1413153]\n",
      "loss: 0.469133  [51456/1413153]\n",
      "loss: 0.456488  [77056/1413153]\n",
      "loss: 0.447261  [102656/1413153]\n",
      "loss: 0.447523  [128256/1413153]\n",
      "loss: 0.452155  [153856/1413153]\n",
      "loss: 0.404196  [179456/1413153]\n",
      "loss: 0.502482  [205056/1413153]\n",
      "loss: 0.494957  [230656/1413153]\n",
      "loss: 0.413911  [256256/1413153]\n",
      "loss: 0.447632  [281856/1413153]\n",
      "loss: 0.459482  [307456/1413153]\n",
      "loss: 0.510561  [333056/1413153]\n",
      "loss: 0.486830  [358656/1413153]\n",
      "loss: 0.486164  [384256/1413153]\n",
      "loss: 0.475780  [409856/1413153]\n",
      "loss: 0.433763  [435456/1413153]\n",
      "loss: 0.426582  [461056/1413153]\n",
      "loss: 0.530512  [486656/1413153]\n",
      "loss: 0.445207  [512256/1413153]\n",
      "loss: 0.440891  [537856/1413153]\n",
      "loss: 0.507090  [563456/1413153]\n",
      "loss: 0.455119  [589056/1413153]\n",
      "loss: 0.433061  [614656/1413153]\n",
      "loss: 0.436439  [640256/1413153]\n",
      "loss: 0.530731  [665856/1413153]\n",
      "loss: 0.537778  [691456/1413153]\n",
      "loss: 0.482822  [717056/1413153]\n",
      "loss: 0.474090  [742656/1413153]\n",
      "loss: 0.527330  [768256/1413153]\n",
      "loss: 0.488150  [793856/1413153]\n",
      "loss: 0.420088  [819456/1413153]\n",
      "loss: 0.436368  [845056/1413153]\n",
      "loss: 0.543196  [870656/1413153]\n",
      "loss: 0.489856  [896256/1413153]\n",
      "loss: 0.510996  [921856/1413153]\n",
      "loss: 0.408730  [947456/1413153]\n",
      "loss: 0.490322  [973056/1413153]\n",
      "loss: 0.484380  [998656/1413153]\n",
      "loss: 0.488709  [1024256/1413153]\n",
      "loss: 0.454900  [1049856/1413153]\n",
      "loss: 0.509777  [1075456/1413153]\n",
      "loss: 0.432812  [1101056/1413153]\n",
      "loss: 0.469836  [1126656/1413153]\n",
      "loss: 0.414888  [1152256/1413153]\n",
      "loss: 0.497654  [1177856/1413153]\n",
      "loss: 0.446096  [1203456/1413153]\n",
      "loss: 0.490242  [1229056/1413153]\n",
      "loss: 0.479119  [1254656/1413153]\n",
      "loss: 0.431772  [1280256/1413153]\n",
      "loss: 0.427196  [1305856/1413153]\n",
      "loss: 0.472121  [1331456/1413153]\n",
      "loss: 0.441731  [1357056/1413153]\n",
      "loss: 0.381807  [1382656/1413153]\n",
      "loss: 0.431396  [1408256/1413153]\n",
      "Avg loss on test: 0.465519 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.424005  [  256/1413153]\n",
      "loss: 0.483392  [25856/1413153]\n",
      "loss: 0.415301  [51456/1413153]\n",
      "loss: 0.484210  [77056/1413153]\n",
      "loss: 0.467060  [102656/1413153]\n",
      "loss: 0.455914  [128256/1413153]\n",
      "loss: 0.459376  [153856/1413153]\n",
      "loss: 0.443336  [179456/1413153]\n",
      "loss: 0.507657  [205056/1413153]\n",
      "loss: 0.517988  [230656/1413153]\n",
      "loss: 0.486867  [256256/1413153]\n",
      "loss: 0.451137  [281856/1413153]\n",
      "loss: 0.416265  [307456/1413153]\n",
      "loss: 0.403305  [333056/1413153]\n",
      "loss: 0.385297  [358656/1413153]\n",
      "loss: 0.441303  [384256/1413153]\n",
      "loss: 0.483248  [409856/1413153]\n",
      "loss: 0.506296  [435456/1413153]\n",
      "loss: 0.423108  [461056/1413153]\n",
      "loss: 0.446969  [486656/1413153]\n",
      "loss: 0.439234  [512256/1413153]\n",
      "loss: 0.462261  [537856/1413153]\n",
      "loss: 0.451664  [563456/1413153]\n",
      "loss: 0.465166  [589056/1413153]\n",
      "loss: 0.476665  [614656/1413153]\n",
      "loss: 0.423782  [640256/1413153]\n",
      "loss: 0.420128  [665856/1413153]\n",
      "loss: 0.519214  [691456/1413153]\n",
      "loss: 0.486971  [717056/1413153]\n",
      "loss: 0.421317  [742656/1413153]\n",
      "loss: 0.462895  [768256/1413153]\n",
      "loss: 0.513836  [793856/1413153]\n",
      "loss: 0.403015  [819456/1413153]\n",
      "loss: 0.503011  [845056/1413153]\n",
      "loss: 0.468914  [870656/1413153]\n",
      "loss: 0.465283  [896256/1413153]\n",
      "loss: 0.430716  [921856/1413153]\n",
      "loss: 0.448917  [947456/1413153]\n",
      "loss: 0.483758  [973056/1413153]\n",
      "loss: 0.386355  [998656/1413153]\n",
      "loss: 0.507592  [1024256/1413153]\n",
      "loss: 0.497934  [1049856/1413153]\n",
      "loss: 0.525572  [1075456/1413153]\n",
      "loss: 0.435743  [1101056/1413153]\n",
      "loss: 0.486629  [1126656/1413153]\n",
      "loss: 0.475586  [1152256/1413153]\n",
      "loss: 0.496158  [1177856/1413153]\n",
      "loss: 0.474500  [1203456/1413153]\n",
      "loss: 0.494444  [1229056/1413153]\n",
      "loss: 0.453168  [1254656/1413153]\n",
      "loss: 0.441341  [1280256/1413153]\n",
      "loss: 0.473671  [1305856/1413153]\n",
      "loss: 0.522928  [1331456/1413153]\n",
      "loss: 0.399435  [1357056/1413153]\n",
      "loss: 0.492888  [1382656/1413153]\n",
      "loss: 0.520270  [1408256/1413153]\n",
      "Avg loss on test: 0.465459 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.462546  [  256/1413153]\n",
      "loss: 0.472548  [25856/1413153]\n",
      "loss: 0.403596  [51456/1413153]\n",
      "loss: 0.469801  [77056/1413153]\n",
      "loss: 0.469162  [102656/1413153]\n",
      "loss: 0.414640  [128256/1413153]\n",
      "loss: 0.465697  [153856/1413153]\n",
      "loss: 0.426677  [179456/1413153]\n",
      "loss: 0.557153  [205056/1413153]\n",
      "loss: 0.492523  [230656/1413153]\n",
      "loss: 0.474408  [256256/1413153]\n",
      "loss: 0.494427  [281856/1413153]\n",
      "loss: 0.529780  [307456/1413153]\n",
      "loss: 0.469363  [333056/1413153]\n",
      "loss: 0.469320  [358656/1413153]\n",
      "loss: 0.422229  [384256/1413153]\n",
      "loss: 0.443615  [409856/1413153]\n",
      "loss: 0.412658  [435456/1413153]\n",
      "loss: 0.432700  [461056/1413153]\n",
      "loss: 0.433728  [486656/1413153]\n",
      "loss: 0.480929  [512256/1413153]\n",
      "loss: 0.508790  [537856/1413153]\n",
      "loss: 0.514004  [563456/1413153]\n",
      "loss: 0.437680  [589056/1413153]\n",
      "loss: 0.470315  [614656/1413153]\n",
      "loss: 0.397603  [640256/1413153]\n",
      "loss: 0.558352  [665856/1413153]\n",
      "loss: 0.452116  [691456/1413153]\n",
      "loss: 0.461897  [717056/1413153]\n",
      "loss: 0.483526  [742656/1413153]\n",
      "loss: 0.442200  [768256/1413153]\n",
      "loss: 0.432728  [793856/1413153]\n",
      "loss: 0.482797  [819456/1413153]\n",
      "loss: 0.497333  [845056/1413153]\n",
      "loss: 0.419980  [870656/1413153]\n",
      "loss: 0.439448  [896256/1413153]\n",
      "loss: 0.559600  [921856/1413153]\n",
      "loss: 0.560567  [947456/1413153]\n",
      "loss: 0.503439  [973056/1413153]\n",
      "loss: 0.497616  [998656/1413153]\n",
      "loss: 0.529422  [1024256/1413153]\n",
      "loss: 0.489447  [1049856/1413153]\n",
      "loss: 0.514135  [1075456/1413153]\n",
      "loss: 0.488791  [1101056/1413153]\n",
      "loss: 0.420969  [1126656/1413153]\n",
      "loss: 0.443218  [1152256/1413153]\n",
      "loss: 0.468095  [1177856/1413153]\n",
      "loss: 0.421412  [1203456/1413153]\n",
      "loss: 0.514256  [1229056/1413153]\n",
      "loss: 0.514525  [1254656/1413153]\n",
      "loss: 0.482058  [1280256/1413153]\n",
      "loss: 0.510637  [1305856/1413153]\n",
      "loss: 0.446036  [1331456/1413153]\n",
      "loss: 0.478354  [1357056/1413153]\n",
      "loss: 0.484050  [1382656/1413153]\n",
      "loss: 0.477296  [1408256/1413153]\n",
      "Avg loss on test: 0.465397 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NCFRecommender(unique_users, unique_items)\n",
    "model.fit(train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = model.train_losses\n",
    "eval_losses = model.eval_losses\n",
    "epochs = model.epochs\n",
    "\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, epochs + 1), eval_losses, label=\"Testing Loss\")\n",
    "plt.xticks(ticks=np.arange(0, epochs + 1, 2))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hit Ratio@10': 0.00016777622677977022,\n",
       " 'NDCG@10': 5.344185010828497e-05,\n",
       " 'Recall@10': 0.0001519573253976776}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import Evaluation\n",
    "\n",
    "evaluator = Evaluation(predictions=predictions, ground_truth=ground_truth, k=10)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
