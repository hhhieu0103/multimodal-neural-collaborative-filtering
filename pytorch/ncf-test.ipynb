{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import NCFDataset\n",
    "from recom_ncf import NCFRecommender\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "app_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "voted_up",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "timestamp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6702cdf6-fe1c-410b-8203-3bdd98c692b9",
       "rows": [
        [
         "0",
         "76561197960432447",
         "10",
         "True",
         "1738278781",
         "A legendary tactical shooter that shaped the genre. Simple yet deep gameplay, excellent weapon balance, and iconic maps keep the game relevant even today. Pure nostalgia and classic FPS action."
        ],
        [
         "1",
         "76561198071230926",
         "10",
         "True",
         "1736206418",
         "The best CS sure, but server browser is the illusion of choice and leads you to the same **** server. Use gametracker or something"
        ],
        [
         "2",
         "76561198206216352",
         "10",
         "True",
         "1738041574",
         "Some of the best memories of my childhood were made in pixels, with friends I only knew through a screen. Time moves on, but those moments are forever frozen in time."
        ],
        [
         "3",
         "76561198110801124",
         "10",
         "True",
         "1738015332",
         "This game feels so much better than CS2. I know this game still gets FACEIT/ESEA-type treatment from services in the EU, but it would be cool if it got such services in NA."
        ],
        [
         "4",
         "76561199813732773",
         "10",
         "True",
         "1737853720",
         "its very fun to play you can make friends out of it i have lots of maps i like i like how theres diffrent teams to choose from idk what else to say its just fun"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960432447</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1738278781</td>\n",
       "      <td>A legendary tactical shooter that shaped the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561198071230926</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1736206418</td>\n",
       "      <td>The best CS sure, but server browser is the il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198206216352</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1738041574</td>\n",
       "      <td>Some of the best memories of my childhood were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198110801124</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1738015332</td>\n",
       "      <td>This game feels so much better than CS2. I kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561199813732773</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1737853720</td>\n",
       "      <td>its very fun to play you can make friends out ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author_id  app_id  voted_up   timestamp  \\\n",
       "0  76561197960432447      10      True  1738278781   \n",
       "1  76561198071230926      10      True  1736206418   \n",
       "2  76561198206216352      10      True  1738041574   \n",
       "3  76561198110801124      10      True  1738015332   \n",
       "4  76561199813732773      10      True  1737853720   \n",
       "\n",
       "                                              review  \n",
       "0  A legendary tactical shooter that shaped the g...  \n",
       "1  The best CS sure, but server browser is the il...  \n",
       "2  Some of the best memories of my childhood were...  \n",
       "3  This game feels so much better than CS2. I kno...  \n",
       "4  its very fun to play you can make friends out ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/review-raw.csv')[['author_id', 'app_id', 'voted_up', 'timestamp', 'review']].copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping user id and app id to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_map = {u: i for i, u in enumerate(df['author_id'].unique())}\n",
    "item_map = {i: j for j, i in enumerate(df['app_id'].unique())}\n",
    "\n",
    "df['user_idx'] = np.array([user_map[u] for u in df['author_id']])\n",
    "df['item_idx'] = np.array([item_map[i] for i in df['app_id']])\n",
    "df['rating_int'] = df['voted_up'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_eval, df_test = train_test_split(df[['user_idx', 'item_idx', 'rating_int']], test_size=0.1, random_state=42)\n",
    "df_train, df_eval = train_test_split(df_train_eval, test_size=(0.1/0.9), random_state=42)\n",
    "\n",
    "train_dataset = NCFDataset(df_train)\n",
    "eval_dataset = NCFDataset(df_eval)\n",
    "test_dataset = NCFDataset(df_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=256, shuffle=False)\n",
    "test_dataloader = DataLoader(eval_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "unique_users = df[\"user_idx\"].unique()\n",
    "unique_items = df[\"item_idx\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1413153, 3)\n",
      "(176645, 3)\n",
      "(176645, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_eval.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.768205  [  256/1413153]\n",
      "loss: 0.747881  [25856/1413153]\n",
      "loss: 0.729712  [51456/1413153]\n",
      "loss: 0.757479  [77056/1413153]\n",
      "loss: 0.734396  [102656/1413153]\n",
      "loss: 0.697407  [128256/1413153]\n",
      "loss: 0.693570  [153856/1413153]\n",
      "loss: 0.660424  [179456/1413153]\n",
      "loss: 0.690643  [205056/1413153]\n",
      "loss: 0.660340  [230656/1413153]\n",
      "loss: 0.634344  [256256/1413153]\n",
      "loss: 0.628638  [281856/1413153]\n",
      "loss: 0.642558  [307456/1413153]\n",
      "loss: 0.636001  [333056/1413153]\n",
      "loss: 0.637851  [358656/1413153]\n",
      "loss: 0.594645  [384256/1413153]\n",
      "loss: 0.598754  [409856/1413153]\n",
      "loss: 0.576477  [435456/1413153]\n",
      "loss: 0.574407  [461056/1413153]\n",
      "loss: 0.589863  [486656/1413153]\n",
      "loss: 0.557897  [512256/1413153]\n",
      "loss: 0.558176  [537856/1413153]\n",
      "loss: 0.552395  [563456/1413153]\n",
      "loss: 0.554169  [589056/1413153]\n",
      "loss: 0.535275  [614656/1413153]\n",
      "loss: 0.560924  [640256/1413153]\n",
      "loss: 0.558120  [665856/1413153]\n",
      "loss: 0.562245  [691456/1413153]\n",
      "loss: 0.515280  [717056/1413153]\n",
      "loss: 0.570593  [742656/1413153]\n",
      "loss: 0.516623  [768256/1413153]\n",
      "loss: 0.564284  [793856/1413153]\n",
      "loss: 0.517991  [819456/1413153]\n",
      "loss: 0.495208  [845056/1413153]\n",
      "loss: 0.503788  [870656/1413153]\n",
      "loss: 0.482395  [896256/1413153]\n",
      "loss: 0.517439  [921856/1413153]\n",
      "loss: 0.490018  [947456/1413153]\n",
      "loss: 0.485114  [973056/1413153]\n",
      "loss: 0.505316  [998656/1413153]\n",
      "loss: 0.551464  [1024256/1413153]\n",
      "loss: 0.480853  [1049856/1413153]\n",
      "loss: 0.506978  [1075456/1413153]\n",
      "loss: 0.493380  [1101056/1413153]\n",
      "loss: 0.488673  [1126656/1413153]\n",
      "loss: 0.497900  [1152256/1413153]\n",
      "loss: 0.462997  [1177856/1413153]\n",
      "loss: 0.492206  [1203456/1413153]\n",
      "loss: 0.565395  [1229056/1413153]\n",
      "loss: 0.459011  [1254656/1413153]\n",
      "loss: 0.497086  [1280256/1413153]\n",
      "loss: 0.446076  [1305856/1413153]\n",
      "loss: 0.483080  [1331456/1413153]\n",
      "loss: 0.497310  [1357056/1413153]\n",
      "loss: 0.428499  [1382656/1413153]\n",
      "loss: 0.482206  [1408256/1413153]\n",
      "Avg loss on test: 0.477436 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.477232  [  256/1413153]\n",
      "loss: 0.474563  [25856/1413153]\n",
      "loss: 0.469326  [51456/1413153]\n",
      "loss: 0.484081  [77056/1413153]\n",
      "loss: 0.487446  [102656/1413153]\n",
      "loss: 0.442572  [128256/1413153]\n",
      "loss: 0.471184  [153856/1413153]\n",
      "loss: 0.416950  [179456/1413153]\n",
      "loss: 0.440939  [205056/1413153]\n",
      "loss: 0.483679  [230656/1413153]\n",
      "loss: 0.480854  [256256/1413153]\n",
      "loss: 0.493431  [281856/1413153]\n",
      "loss: 0.501599  [307456/1413153]\n",
      "loss: 0.503488  [333056/1413153]\n",
      "loss: 0.530445  [358656/1413153]\n",
      "loss: 0.453771  [384256/1413153]\n",
      "loss: 0.454966  [409856/1413153]\n",
      "loss: 0.472849  [435456/1413153]\n",
      "loss: 0.467232  [461056/1413153]\n",
      "loss: 0.498272  [486656/1413153]\n",
      "loss: 0.433500  [512256/1413153]\n",
      "loss: 0.467526  [537856/1413153]\n",
      "loss: 0.455118  [563456/1413153]\n",
      "loss: 0.504832  [589056/1413153]\n",
      "loss: 0.497490  [614656/1413153]\n",
      "loss: 0.447307  [640256/1413153]\n",
      "loss: 0.491500  [665856/1413153]\n",
      "loss: 0.521624  [691456/1413153]\n",
      "loss: 0.494003  [717056/1413153]\n",
      "loss: 0.458543  [742656/1413153]\n",
      "loss: 0.478407  [768256/1413153]\n",
      "loss: 0.520149  [793856/1413153]\n",
      "loss: 0.531357  [819456/1413153]\n",
      "loss: 0.467699  [845056/1413153]\n",
      "loss: 0.484478  [870656/1413153]\n",
      "loss: 0.459599  [896256/1413153]\n",
      "loss: 0.441776  [921856/1413153]\n",
      "loss: 0.479959  [947456/1413153]\n",
      "loss: 0.475600  [973056/1413153]\n",
      "loss: 0.502417  [998656/1413153]\n",
      "loss: 0.407839  [1024256/1413153]\n",
      "loss: 0.442923  [1049856/1413153]\n",
      "loss: 0.461671  [1075456/1413153]\n",
      "loss: 0.443480  [1101056/1413153]\n",
      "loss: 0.444658  [1126656/1413153]\n",
      "loss: 0.471001  [1152256/1413153]\n",
      "loss: 0.439640  [1177856/1413153]\n",
      "loss: 0.499516  [1203456/1413153]\n",
      "loss: 0.452310  [1229056/1413153]\n",
      "loss: 0.449262  [1254656/1413153]\n",
      "loss: 0.523484  [1280256/1413153]\n",
      "loss: 0.469525  [1305856/1413153]\n",
      "loss: 0.528549  [1331456/1413153]\n",
      "loss: 0.526983  [1357056/1413153]\n",
      "loss: 0.525227  [1382656/1413153]\n",
      "loss: 0.464621  [1408256/1413153]\n",
      "Avg loss on test: 0.467411 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.429720  [  256/1413153]\n",
      "loss: 0.438759  [25856/1413153]\n",
      "loss: 0.433225  [51456/1413153]\n",
      "loss: 0.485208  [77056/1413153]\n",
      "loss: 0.447457  [102656/1413153]\n",
      "loss: 0.486701  [128256/1413153]\n",
      "loss: 0.506695  [153856/1413153]\n",
      "loss: 0.484785  [179456/1413153]\n",
      "loss: 0.455118  [205056/1413153]\n",
      "loss: 0.451522  [230656/1413153]\n",
      "loss: 0.421139  [256256/1413153]\n",
      "loss: 0.464964  [281856/1413153]\n",
      "loss: 0.545494  [307456/1413153]\n",
      "loss: 0.502840  [333056/1413153]\n",
      "loss: 0.407172  [358656/1413153]\n",
      "loss: 0.495877  [384256/1413153]\n",
      "loss: 0.464125  [409856/1413153]\n",
      "loss: 0.477635  [435456/1413153]\n",
      "loss: 0.516853  [461056/1413153]\n",
      "loss: 0.426218  [486656/1413153]\n",
      "loss: 0.525775  [512256/1413153]\n",
      "loss: 0.411291  [537856/1413153]\n",
      "loss: 0.544737  [563456/1413153]\n",
      "loss: 0.447005  [589056/1413153]\n",
      "loss: 0.440638  [614656/1413153]\n",
      "loss: 0.450934  [640256/1413153]\n",
      "loss: 0.446287  [665856/1413153]\n",
      "loss: 0.486760  [691456/1413153]\n",
      "loss: 0.522362  [717056/1413153]\n",
      "loss: 0.508108  [742656/1413153]\n",
      "loss: 0.389973  [768256/1413153]\n",
      "loss: 0.485226  [793856/1413153]\n",
      "loss: 0.475908  [819456/1413153]\n",
      "loss: 0.485895  [845056/1413153]\n",
      "loss: 0.452435  [870656/1413153]\n",
      "loss: 0.541588  [896256/1413153]\n",
      "loss: 0.524029  [921856/1413153]\n",
      "loss: 0.470494  [947456/1413153]\n",
      "loss: 0.431313  [973056/1413153]\n",
      "loss: 0.517268  [998656/1413153]\n",
      "loss: 0.477782  [1024256/1413153]\n",
      "loss: 0.527148  [1049856/1413153]\n",
      "loss: 0.473827  [1075456/1413153]\n",
      "loss: 0.470064  [1101056/1413153]\n",
      "loss: 0.352128  [1126656/1413153]\n",
      "loss: 0.418160  [1152256/1413153]\n",
      "loss: 0.500566  [1177856/1413153]\n",
      "loss: 0.422112  [1203456/1413153]\n",
      "loss: 0.537096  [1229056/1413153]\n",
      "loss: 0.507386  [1254656/1413153]\n",
      "loss: 0.461355  [1280256/1413153]\n",
      "loss: 0.511988  [1305856/1413153]\n",
      "loss: 0.518286  [1331456/1413153]\n",
      "loss: 0.460773  [1357056/1413153]\n",
      "loss: 0.475827  [1382656/1413153]\n",
      "loss: 0.436719  [1408256/1413153]\n",
      "Avg loss on test: 0.466846 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.495636  [  256/1413153]\n",
      "loss: 0.555927  [25856/1413153]\n",
      "loss: 0.443176  [51456/1413153]\n",
      "loss: 0.542178  [77056/1413153]\n",
      "loss: 0.412446  [102656/1413153]\n",
      "loss: 0.483877  [128256/1413153]\n",
      "loss: 0.422998  [153856/1413153]\n",
      "loss: 0.465159  [179456/1413153]\n",
      "loss: 0.463783  [205056/1413153]\n",
      "loss: 0.482386  [230656/1413153]\n",
      "loss: 0.457652  [256256/1413153]\n",
      "loss: 0.489927  [281856/1413153]\n",
      "loss: 0.538206  [307456/1413153]\n",
      "loss: 0.552844  [333056/1413153]\n",
      "loss: 0.512876  [358656/1413153]\n",
      "loss: 0.497774  [384256/1413153]\n",
      "loss: 0.484029  [409856/1413153]\n",
      "loss: 0.519572  [435456/1413153]\n",
      "loss: 0.469943  [461056/1413153]\n",
      "loss: 0.499751  [486656/1413153]\n",
      "loss: 0.550765  [512256/1413153]\n",
      "loss: 0.479039  [537856/1413153]\n",
      "loss: 0.469776  [563456/1413153]\n",
      "loss: 0.424527  [589056/1413153]\n",
      "loss: 0.494789  [614656/1413153]\n",
      "loss: 0.495301  [640256/1413153]\n",
      "loss: 0.483233  [665856/1413153]\n",
      "loss: 0.474867  [691456/1413153]\n",
      "loss: 0.489899  [717056/1413153]\n",
      "loss: 0.468392  [742656/1413153]\n",
      "loss: 0.495545  [768256/1413153]\n",
      "loss: 0.464355  [793856/1413153]\n",
      "loss: 0.503677  [819456/1413153]\n",
      "loss: 0.507969  [845056/1413153]\n",
      "loss: 0.502609  [870656/1413153]\n",
      "loss: 0.440339  [896256/1413153]\n",
      "loss: 0.482752  [921856/1413153]\n",
      "loss: 0.519375  [947456/1413153]\n",
      "loss: 0.425149  [973056/1413153]\n",
      "loss: 0.508017  [998656/1413153]\n",
      "loss: 0.462009  [1024256/1413153]\n",
      "loss: 0.472343  [1049856/1413153]\n",
      "loss: 0.478649  [1075456/1413153]\n",
      "loss: 0.461389  [1101056/1413153]\n",
      "loss: 0.435590  [1126656/1413153]\n",
      "loss: 0.458591  [1152256/1413153]\n",
      "loss: 0.465608  [1177856/1413153]\n",
      "loss: 0.474781  [1203456/1413153]\n",
      "loss: 0.501143  [1229056/1413153]\n",
      "loss: 0.470586  [1254656/1413153]\n",
      "loss: 0.524259  [1280256/1413153]\n",
      "loss: 0.435996  [1305856/1413153]\n",
      "loss: 0.467694  [1331456/1413153]\n",
      "loss: 0.456781  [1357056/1413153]\n",
      "loss: 0.477203  [1382656/1413153]\n",
      "loss: 0.532549  [1408256/1413153]\n",
      "Avg loss on test: 0.466635 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.429349  [  256/1413153]\n",
      "loss: 0.523551  [25856/1413153]\n",
      "loss: 0.514166  [51456/1413153]\n",
      "loss: 0.560827  [77056/1413153]\n",
      "loss: 0.481368  [102656/1413153]\n",
      "loss: 0.499144  [128256/1413153]\n",
      "loss: 0.463546  [153856/1413153]\n",
      "loss: 0.479286  [179456/1413153]\n",
      "loss: 0.520474  [205056/1413153]\n",
      "loss: 0.477804  [230656/1413153]\n",
      "loss: 0.444563  [256256/1413153]\n",
      "loss: 0.498376  [281856/1413153]\n",
      "loss: 0.488071  [307456/1413153]\n",
      "loss: 0.451570  [333056/1413153]\n",
      "loss: 0.461609  [358656/1413153]\n",
      "loss: 0.413303  [384256/1413153]\n",
      "loss: 0.469731  [409856/1413153]\n",
      "loss: 0.457548  [435456/1413153]\n",
      "loss: 0.441594  [461056/1413153]\n",
      "loss: 0.481475  [486656/1413153]\n",
      "loss: 0.499894  [512256/1413153]\n",
      "loss: 0.432564  [537856/1413153]\n",
      "loss: 0.469285  [563456/1413153]\n",
      "loss: 0.468385  [589056/1413153]\n",
      "loss: 0.456391  [614656/1413153]\n",
      "loss: 0.443595  [640256/1413153]\n",
      "loss: 0.460689  [665856/1413153]\n",
      "loss: 0.498168  [691456/1413153]\n",
      "loss: 0.504270  [717056/1413153]\n",
      "loss: 0.514537  [742656/1413153]\n",
      "loss: 0.457830  [768256/1413153]\n",
      "loss: 0.488061  [793856/1413153]\n",
      "loss: 0.407761  [819456/1413153]\n",
      "loss: 0.428329  [845056/1413153]\n",
      "loss: 0.484191  [870656/1413153]\n",
      "loss: 0.548332  [896256/1413153]\n",
      "loss: 0.471603  [921856/1413153]\n",
      "loss: 0.383204  [947456/1413153]\n",
      "loss: 0.475793  [973056/1413153]\n",
      "loss: 0.524384  [998656/1413153]\n",
      "loss: 0.462624  [1024256/1413153]\n",
      "loss: 0.524759  [1049856/1413153]\n",
      "loss: 0.450909  [1075456/1413153]\n",
      "loss: 0.411884  [1101056/1413153]\n",
      "loss: 0.465746  [1126656/1413153]\n",
      "loss: 0.415331  [1152256/1413153]\n",
      "loss: 0.482862  [1177856/1413153]\n",
      "loss: 0.427496  [1203456/1413153]\n",
      "loss: 0.470976  [1229056/1413153]\n",
      "loss: 0.494670  [1254656/1413153]\n",
      "loss: 0.447657  [1280256/1413153]\n",
      "loss: 0.454304  [1305856/1413153]\n",
      "loss: 0.452843  [1331456/1413153]\n",
      "loss: 0.439811  [1357056/1413153]\n",
      "loss: 0.429434  [1382656/1413153]\n",
      "loss: 0.478345  [1408256/1413153]\n",
      "Avg loss on test: 0.466500 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.428953  [  256/1413153]\n",
      "loss: 0.480594  [25856/1413153]\n",
      "loss: 0.526576  [51456/1413153]\n",
      "loss: 0.435301  [77056/1413153]\n",
      "loss: 0.471140  [102656/1413153]\n",
      "loss: 0.484179  [128256/1413153]\n",
      "loss: 0.458465  [153856/1413153]\n",
      "loss: 0.422065  [179456/1413153]\n",
      "loss: 0.477708  [205056/1413153]\n",
      "loss: 0.502796  [230656/1413153]\n",
      "loss: 0.470358  [256256/1413153]\n",
      "loss: 0.494422  [281856/1413153]\n",
      "loss: 0.495627  [307456/1413153]\n",
      "loss: 0.494731  [333056/1413153]\n",
      "loss: 0.526895  [358656/1413153]\n",
      "loss: 0.463749  [384256/1413153]\n",
      "loss: 0.473195  [409856/1413153]\n",
      "loss: 0.502944  [435456/1413153]\n",
      "loss: 0.415870  [461056/1413153]\n",
      "loss: 0.429346  [486656/1413153]\n",
      "loss: 0.498902  [512256/1413153]\n",
      "loss: 0.489852  [537856/1413153]\n",
      "loss: 0.461152  [563456/1413153]\n",
      "loss: 0.555648  [589056/1413153]\n",
      "loss: 0.458784  [614656/1413153]\n",
      "loss: 0.434666  [640256/1413153]\n",
      "loss: 0.464996  [665856/1413153]\n",
      "loss: 0.491731  [691456/1413153]\n",
      "loss: 0.458779  [717056/1413153]\n",
      "loss: 0.436227  [742656/1413153]\n",
      "loss: 0.516567  [768256/1413153]\n",
      "loss: 0.438010  [793856/1413153]\n",
      "loss: 0.488446  [819456/1413153]\n",
      "loss: 0.423206  [845056/1413153]\n",
      "loss: 0.524607  [870656/1413153]\n",
      "loss: 0.478600  [896256/1413153]\n",
      "loss: 0.477683  [921856/1413153]\n",
      "loss: 0.495667  [947456/1413153]\n",
      "loss: 0.496743  [973056/1413153]\n",
      "loss: 0.438344  [998656/1413153]\n",
      "loss: 0.467779  [1024256/1413153]\n",
      "loss: 0.472240  [1049856/1413153]\n",
      "loss: 0.470137  [1075456/1413153]\n",
      "loss: 0.454066  [1101056/1413153]\n",
      "loss: 0.443523  [1126656/1413153]\n",
      "loss: 0.485793  [1152256/1413153]\n",
      "loss: 0.537450  [1177856/1413153]\n",
      "loss: 0.458767  [1203456/1413153]\n",
      "loss: 0.520975  [1229056/1413153]\n",
      "loss: 0.466859  [1254656/1413153]\n",
      "loss: 0.434469  [1280256/1413153]\n",
      "loss: 0.526980  [1305856/1413153]\n",
      "loss: 0.472854  [1331456/1413153]\n",
      "loss: 0.431746  [1357056/1413153]\n",
      "loss: 0.418878  [1382656/1413153]\n",
      "loss: 0.478309  [1408256/1413153]\n",
      "Avg loss on test: 0.466387 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.472075  [  256/1413153]\n",
      "loss: 0.435060  [25856/1413153]\n",
      "loss: 0.476003  [51456/1413153]\n",
      "loss: 0.459765  [77056/1413153]\n",
      "loss: 0.435734  [102656/1413153]\n",
      "loss: 0.442062  [128256/1413153]\n",
      "loss: 0.478727  [153856/1413153]\n",
      "loss: 0.499607  [179456/1413153]\n",
      "loss: 0.488784  [205056/1413153]\n",
      "loss: 0.470681  [230656/1413153]\n",
      "loss: 0.571747  [256256/1413153]\n",
      "loss: 0.458218  [281856/1413153]\n",
      "loss: 0.562301  [307456/1413153]\n",
      "loss: 0.445177  [333056/1413153]\n",
      "loss: 0.461374  [358656/1413153]\n",
      "loss: 0.436158  [384256/1413153]\n",
      "loss: 0.471258  [409856/1413153]\n",
      "loss: 0.448262  [435456/1413153]\n",
      "loss: 0.480753  [461056/1413153]\n",
      "loss: 0.493707  [486656/1413153]\n",
      "loss: 0.433788  [512256/1413153]\n",
      "loss: 0.447377  [537856/1413153]\n",
      "loss: 0.476798  [563456/1413153]\n",
      "loss: 0.481710  [589056/1413153]\n",
      "loss: 0.430586  [614656/1413153]\n",
      "loss: 0.508436  [640256/1413153]\n",
      "loss: 0.478515  [665856/1413153]\n",
      "loss: 0.451826  [691456/1413153]\n",
      "loss: 0.472527  [717056/1413153]\n",
      "loss: 0.417221  [742656/1413153]\n",
      "loss: 0.440728  [768256/1413153]\n",
      "loss: 0.405681  [793856/1413153]\n",
      "loss: 0.482663  [819456/1413153]\n",
      "loss: 0.477069  [845056/1413153]\n",
      "loss: 0.439636  [870656/1413153]\n",
      "loss: 0.410765  [896256/1413153]\n",
      "loss: 0.437905  [921856/1413153]\n",
      "loss: 0.471451  [947456/1413153]\n",
      "loss: 0.470102  [973056/1413153]\n",
      "loss: 0.541905  [998656/1413153]\n",
      "loss: 0.461599  [1024256/1413153]\n",
      "loss: 0.537601  [1049856/1413153]\n",
      "loss: 0.477838  [1075456/1413153]\n",
      "loss: 0.518472  [1101056/1413153]\n",
      "loss: 0.481795  [1126656/1413153]\n",
      "loss: 0.422586  [1152256/1413153]\n",
      "loss: 0.503797  [1177856/1413153]\n",
      "loss: 0.405436  [1203456/1413153]\n",
      "loss: 0.422301  [1229056/1413153]\n",
      "loss: 0.410742  [1254656/1413153]\n",
      "loss: 0.451665  [1280256/1413153]\n",
      "loss: 0.518595  [1305856/1413153]\n",
      "loss: 0.465825  [1331456/1413153]\n",
      "loss: 0.429561  [1357056/1413153]\n",
      "loss: 0.501007  [1382656/1413153]\n",
      "loss: 0.442724  [1408256/1413153]\n",
      "Avg loss on test: 0.466294 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.482700  [  256/1413153]\n",
      "loss: 0.429371  [25856/1413153]\n",
      "loss: 0.547186  [51456/1413153]\n",
      "loss: 0.482835  [77056/1413153]\n",
      "loss: 0.404321  [102656/1413153]\n",
      "loss: 0.495905  [128256/1413153]\n",
      "loss: 0.475029  [153856/1413153]\n",
      "loss: 0.406535  [179456/1413153]\n",
      "loss: 0.453067  [205056/1413153]\n",
      "loss: 0.411035  [230656/1413153]\n",
      "loss: 0.398414  [256256/1413153]\n",
      "loss: 0.475114  [281856/1413153]\n",
      "loss: 0.493066  [307456/1413153]\n",
      "loss: 0.422593  [333056/1413153]\n",
      "loss: 0.427906  [358656/1413153]\n",
      "loss: 0.437222  [384256/1413153]\n",
      "loss: 0.474596  [409856/1413153]\n",
      "loss: 0.483095  [435456/1413153]\n",
      "loss: 0.531438  [461056/1413153]\n",
      "loss: 0.406373  [486656/1413153]\n",
      "loss: 0.487374  [512256/1413153]\n",
      "loss: 0.464355  [537856/1413153]\n",
      "loss: 0.430505  [563456/1413153]\n",
      "loss: 0.482093  [589056/1413153]\n",
      "loss: 0.433130  [614656/1413153]\n",
      "loss: 0.477058  [640256/1413153]\n",
      "loss: 0.470906  [665856/1413153]\n",
      "loss: 0.452528  [691456/1413153]\n",
      "loss: 0.458724  [717056/1413153]\n",
      "loss: 0.458989  [742656/1413153]\n",
      "loss: 0.453139  [768256/1413153]\n",
      "loss: 0.400200  [793856/1413153]\n",
      "loss: 0.521374  [819456/1413153]\n",
      "loss: 0.489803  [845056/1413153]\n",
      "loss: 0.453733  [870656/1413153]\n",
      "loss: 0.496632  [896256/1413153]\n",
      "loss: 0.560240  [921856/1413153]\n",
      "loss: 0.409844  [947456/1413153]\n",
      "loss: 0.415736  [973056/1413153]\n",
      "loss: 0.440620  [998656/1413153]\n",
      "loss: 0.459946  [1024256/1413153]\n",
      "loss: 0.489179  [1049856/1413153]\n",
      "loss: 0.454223  [1075456/1413153]\n",
      "loss: 0.488629  [1101056/1413153]\n",
      "loss: 0.493410  [1126656/1413153]\n",
      "loss: 0.467751  [1152256/1413153]\n",
      "loss: 0.471507  [1177856/1413153]\n",
      "loss: 0.467365  [1203456/1413153]\n",
      "loss: 0.446357  [1229056/1413153]\n",
      "loss: 0.472816  [1254656/1413153]\n",
      "loss: 0.469546  [1280256/1413153]\n",
      "loss: 0.510763  [1305856/1413153]\n",
      "loss: 0.470775  [1331456/1413153]\n",
      "loss: 0.511074  [1357056/1413153]\n",
      "loss: 0.495578  [1382656/1413153]\n",
      "loss: 0.470405  [1408256/1413153]\n",
      "Avg loss on test: 0.466197 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.462408  [  256/1413153]\n",
      "loss: 0.371919  [25856/1413153]\n",
      "loss: 0.501305  [51456/1413153]\n",
      "loss: 0.476011  [77056/1413153]\n",
      "loss: 0.502244  [102656/1413153]\n",
      "loss: 0.460337  [128256/1413153]\n",
      "loss: 0.501570  [153856/1413153]\n",
      "loss: 0.541937  [179456/1413153]\n",
      "loss: 0.492936  [205056/1413153]\n",
      "loss: 0.476691  [230656/1413153]\n",
      "loss: 0.471148  [256256/1413153]\n",
      "loss: 0.489353  [281856/1413153]\n",
      "loss: 0.482711  [307456/1413153]\n",
      "loss: 0.469010  [333056/1413153]\n",
      "loss: 0.444350  [358656/1413153]\n",
      "loss: 0.472191  [384256/1413153]\n",
      "loss: 0.422924  [409856/1413153]\n",
      "loss: 0.451367  [435456/1413153]\n",
      "loss: 0.495399  [461056/1413153]\n",
      "loss: 0.539993  [486656/1413153]\n",
      "loss: 0.483359  [512256/1413153]\n",
      "loss: 0.458171  [537856/1413153]\n",
      "loss: 0.471979  [563456/1413153]\n",
      "loss: 0.464624  [589056/1413153]\n",
      "loss: 0.466816  [614656/1413153]\n",
      "loss: 0.435780  [640256/1413153]\n",
      "loss: 0.497151  [665856/1413153]\n",
      "loss: 0.489584  [691456/1413153]\n",
      "loss: 0.520389  [717056/1413153]\n",
      "loss: 0.507986  [742656/1413153]\n",
      "loss: 0.505339  [768256/1413153]\n",
      "loss: 0.475364  [793856/1413153]\n",
      "loss: 0.447816  [819456/1413153]\n",
      "loss: 0.479694  [845056/1413153]\n",
      "loss: 0.471491  [870656/1413153]\n",
      "loss: 0.465972  [896256/1413153]\n",
      "loss: 0.427358  [921856/1413153]\n",
      "loss: 0.512380  [947456/1413153]\n",
      "loss: 0.447011  [973056/1413153]\n",
      "loss: 0.472096  [998656/1413153]\n",
      "loss: 0.533678  [1024256/1413153]\n",
      "loss: 0.483615  [1049856/1413153]\n",
      "loss: 0.494614  [1075456/1413153]\n",
      "loss: 0.418638  [1101056/1413153]\n",
      "loss: 0.467597  [1126656/1413153]\n",
      "loss: 0.466610  [1152256/1413153]\n",
      "loss: 0.446702  [1177856/1413153]\n",
      "loss: 0.458317  [1203456/1413153]\n",
      "loss: 0.445469  [1229056/1413153]\n",
      "loss: 0.465012  [1254656/1413153]\n",
      "loss: 0.427371  [1280256/1413153]\n",
      "loss: 0.503176  [1305856/1413153]\n",
      "loss: 0.510679  [1331456/1413153]\n",
      "loss: 0.464757  [1357056/1413153]\n",
      "loss: 0.431075  [1382656/1413153]\n",
      "loss: 0.497778  [1408256/1413153]\n",
      "Avg loss on test: 0.466112 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.453930  [  256/1413153]\n",
      "loss: 0.437280  [25856/1413153]\n",
      "loss: 0.464336  [51456/1413153]\n",
      "loss: 0.432380  [77056/1413153]\n",
      "loss: 0.450566  [102656/1413153]\n",
      "loss: 0.458510  [128256/1413153]\n",
      "loss: 0.517571  [153856/1413153]\n",
      "loss: 0.462418  [179456/1413153]\n",
      "loss: 0.480956  [205056/1413153]\n",
      "loss: 0.483037  [230656/1413153]\n",
      "loss: 0.485071  [256256/1413153]\n",
      "loss: 0.494694  [281856/1413153]\n",
      "loss: 0.436399  [307456/1413153]\n",
      "loss: 0.428846  [333056/1413153]\n",
      "loss: 0.519527  [358656/1413153]\n",
      "loss: 0.464322  [384256/1413153]\n",
      "loss: 0.490678  [409856/1413153]\n",
      "loss: 0.423646  [435456/1413153]\n",
      "loss: 0.481370  [461056/1413153]\n",
      "loss: 0.417412  [486656/1413153]\n",
      "loss: 0.423127  [512256/1413153]\n",
      "loss: 0.480927  [537856/1413153]\n",
      "loss: 0.470743  [563456/1413153]\n",
      "loss: 0.458689  [589056/1413153]\n",
      "loss: 0.457425  [614656/1413153]\n",
      "loss: 0.504968  [640256/1413153]\n",
      "loss: 0.483774  [665856/1413153]\n",
      "loss: 0.464043  [691456/1413153]\n",
      "loss: 0.498966  [717056/1413153]\n",
      "loss: 0.475119  [742656/1413153]\n",
      "loss: 0.427342  [768256/1413153]\n",
      "loss: 0.457681  [793856/1413153]\n",
      "loss: 0.409186  [819456/1413153]\n",
      "loss: 0.491566  [845056/1413153]\n",
      "loss: 0.460641  [870656/1413153]\n",
      "loss: 0.451539  [896256/1413153]\n",
      "loss: 0.470922  [921856/1413153]\n",
      "loss: 0.542853  [947456/1413153]\n",
      "loss: 0.375231  [973056/1413153]\n",
      "loss: 0.481494  [998656/1413153]\n",
      "loss: 0.534043  [1024256/1413153]\n",
      "loss: 0.500004  [1049856/1413153]\n",
      "loss: 0.435122  [1075456/1413153]\n",
      "loss: 0.483931  [1101056/1413153]\n",
      "loss: 0.431096  [1126656/1413153]\n",
      "loss: 0.416850  [1152256/1413153]\n",
      "loss: 0.505948  [1177856/1413153]\n",
      "loss: 0.487005  [1203456/1413153]\n",
      "loss: 0.522386  [1229056/1413153]\n",
      "loss: 0.447901  [1254656/1413153]\n",
      "loss: 0.402318  [1280256/1413153]\n",
      "loss: 0.476802  [1305856/1413153]\n",
      "loss: 0.509206  [1331456/1413153]\n",
      "loss: 0.413083  [1357056/1413153]\n",
      "loss: 0.478704  [1382656/1413153]\n",
      "loss: 0.427394  [1408256/1413153]\n",
      "Avg loss on test: 0.466044 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.484531  [  256/1413153]\n",
      "loss: 0.472445  [25856/1413153]\n",
      "loss: 0.472181  [51456/1413153]\n",
      "loss: 0.456097  [77056/1413153]\n",
      "loss: 0.482526  [102656/1413153]\n",
      "loss: 0.535924  [128256/1413153]\n",
      "loss: 0.448496  [153856/1413153]\n",
      "loss: 0.443642  [179456/1413153]\n",
      "loss: 0.462733  [205056/1413153]\n",
      "loss: 0.432885  [230656/1413153]\n",
      "loss: 0.436356  [256256/1413153]\n",
      "loss: 0.563414  [281856/1413153]\n",
      "loss: 0.513979  [307456/1413153]\n",
      "loss: 0.421895  [333056/1413153]\n",
      "loss: 0.516480  [358656/1413153]\n",
      "loss: 0.459168  [384256/1413153]\n",
      "loss: 0.546637  [409856/1413153]\n",
      "loss: 0.435623  [435456/1413153]\n",
      "loss: 0.400508  [461056/1413153]\n",
      "loss: 0.493527  [486656/1413153]\n",
      "loss: 0.482697  [512256/1413153]\n",
      "loss: 0.504948  [537856/1413153]\n",
      "loss: 0.465668  [563456/1413153]\n",
      "loss: 0.443323  [589056/1413153]\n",
      "loss: 0.512510  [614656/1413153]\n",
      "loss: 0.471860  [640256/1413153]\n"
     ]
    }
   ],
   "source": [
    "model = NCFRecommender(unique_users, unique_items)\n",
    "model.fit(train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = model.train_losses\n",
    "eval_losses = model.eval_losses\n",
    "epochs = model.epochs\n",
    "\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, epochs + 1), eval_losses, label=\"Testing Loss\")\n",
    "plt.xticks(ticks=np.arange(0, epochs + 1, 2))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7973], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(users, items):\n",
    "    model.model.eval()\n",
    "    users = torch.tensor(users, dtype=torch.long)\n",
    "    items = torch.tensor(items, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        users = users.to(model.device)\n",
    "        items = items.to(model.device)\n",
    "        predictions =model.model(users, items)\n",
    "    return predictions\n",
    "\n",
    "predict([0], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_users(users, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Generate predictions for all items for each user\n",
    "    \n",
    "    Args:\n",
    "        model: Trained NCF model\n",
    "        users: List of user IDs\n",
    "        all_items: Tensor of all item IDs\n",
    "        timestamp: Current timestamp or tensor of timestamps (one per user)\n",
    "        device: Device to run prediction on\n",
    "        batch_size: Batch size for prediction\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping user IDs to tensors of scores for all items\n",
    "    \"\"\"\n",
    "    model.model.eval()\n",
    "    predictions = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Process each user\n",
    "        for user_id in users:\n",
    "            user_tensor = torch.full((len(model.unique_items),), user_id, dtype=torch.long)\n",
    "            \n",
    "            all_scores = []\n",
    "            for i in range(0, len(model.unique_items), batch_size):\n",
    "                batch_items = model.unique_items[i:i+batch_size]\n",
    "                batch_users = user_tensor[i:i+batch_size]\n",
    "                \n",
    "                # Move to device\n",
    "                batch_users = batch_users.to(model.device)\n",
    "                batch_items = batch_items.to(model.device)\n",
    "                \n",
    "                # Get predictions\n",
    "                batch_scores = model.model(batch_users, batch_items)\n",
    "                all_scores.append(batch_scores.cpu())\n",
    "            \n",
    "            # Combine all batches\n",
    "            user_predictions = torch.cat(all_scores).squeeze()\n",
    "            predictions[user_id] = user_predictions\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "predictions = predict_for_users([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "# Generate predictions and prepare ground truth\n",
    "predictions = {}  # user_id -> ordered list of recommended items\n",
    "ground_truth = {}  # user_id -> set of relevant items from test set\n",
    "k = 10\n",
    "test_unique_users = df_test['user_idx'].unique()\n",
    "\n",
    "# For each user in test set\n",
    "for user_idx in test_unique_users:\n",
    "    relevant_items = set(df_test[df_test['user_idx'] == user_idx]['item_idx'])\n",
    "    ground_truth[user_idx] = relevant_items\n",
    "    \n",
    "    scores = predict_for_users([user_idx])[user_idx].numpy()\n",
    "    top_k_items = []\n",
    "    k = 10\n",
    "    \n",
    "    for item_id, score in enumerate(scores):\n",
    "        # For a min-heap, we use negative score to get highest scores\n",
    "        if len(top_k_items) < k:\n",
    "            heapq.heappush(top_k_items, (score, item_id))\n",
    "        elif score > top_k_items[0][0]:\n",
    "            heapq.heappushpop(top_k_items, (score, item_id))\n",
    "            \n",
    "    # Convert heap to sorted list (highest scores first)\n",
    "    sorted_items = [item_id for score, item_id in sorted(top_k_items, reverse=True)]\n",
    "    \n",
    "    predictions[user_idx] = sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/predictions.json', 'w') as f:\n",
    "    json.dump(predictions, f)\n",
    "    \n",
    "with open('data/ground_truth.json', 'w') as f:\n",
    "    json.dump(ground_truth, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_ratio_at_k(predictions, ground_truth, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Hit Ratio@k for recommendations.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Dictionary mapping user IDs to ordered lists of recommended item IDs\n",
    "        ground_truth: Dictionary mapping user IDs to sets of relevant item IDs\n",
    "        k: Number of top recommendations to consider\n",
    "    \n",
    "    Returns:\n",
    "        Hit Ratio@k score (between 0 and 1)\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    total_users = len(ground_truth)\n",
    "    \n",
    "    for user_idx, true_items in ground_truth.items():\n",
    "        if user_idx not in predictions:\n",
    "            print(f\"User {user_idx} missing from predictions\")\n",
    "            continue\n",
    "            \n",
    "        # Get top-k recommendations for this user\n",
    "        recommended_items = predictions[user_idx][:k]\n",
    "        \n",
    "        # Check if any true items appear in the recommendations\n",
    "        if any(item in true_items for item in recommended_items):\n",
    "            print('True items:', true_items)\n",
    "            print('Recommended items:', recommended_items)\n",
    "            print('='*50)\n",
    "            hits += 1\n",
    "\n",
    "    return hits / total_users if total_users > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_ratio_at_k(predictions, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ndcg_at_k(predictions, ground_truth, k=10):\n",
    "    \"\"\"\n",
    "    Calculate NDCG@k for recommendations.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Dictionary mapping user IDs to ordered lists of recommended item IDs\n",
    "        ground_truth: Dictionary mapping user IDs to sets of relevant item IDs\n",
    "        k: Number of top recommendations to consider\n",
    "    \n",
    "    Returns:\n",
    "        NDCG@k score (between 0 and 1)\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for user_id, true_items in ground_truth.items():\n",
    "        if user_id not in predictions or not true_items:\n",
    "            continue\n",
    "            \n",
    "        # Get top-k recommendations for this user\n",
    "        recommended_items = predictions[user_id][:k]\n",
    "        \n",
    "        # Calculate DCG\n",
    "        dcg = 0\n",
    "        for i, item in enumerate(recommended_items):\n",
    "            if item in true_items:\n",
    "                # Using binary relevance (1 if relevant, 0 if not)\n",
    "                # Position i+1 because we start counting from 0\n",
    "                dcg += 1 / np.log2(i + 2)  # log base 2 of position + 1\n",
    "        \n",
    "        # Calculate ideal DCG (IDCG)\n",
    "        # IDCG is the DCG value if recommendations were perfect\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(min(len(true_items), k)))\n",
    "        \n",
    "        # Calculate NDCG\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "        ndcg_scores.append(ndcg)\n",
    "    \n",
    "    return sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k(predictions, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(predictions, ground_truth, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Recall@k for recommendations.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Dictionary mapping user IDs to ordered lists of recommended item IDs\n",
    "        ground_truth: Dictionary mapping user IDs to sets of relevant item IDs\n",
    "        k: Number of top recommendations to consider\n",
    "    \n",
    "    Returns:\n",
    "        Recall@k score (between 0 and 1)\n",
    "    \"\"\"\n",
    "    recalls = []\n",
    "    \n",
    "    for user_id, true_items in ground_truth.items():\n",
    "        if user_id not in predictions or not true_items:\n",
    "            continue\n",
    "            \n",
    "        # Get top-k recommendations for this user\n",
    "        recommended_items = predictions[user_id][:k]\n",
    "        \n",
    "        # Count relevant items in the recommendations\n",
    "        num_relevant = sum(1 for item in recommended_items if item in true_items)\n",
    "        \n",
    "        # Calculate recall for this user\n",
    "        user_recall = num_relevant / len(true_items)\n",
    "        recalls.append(user_recall)\n",
    "    \n",
    "    return sum(recalls) / len(recalls) if recalls else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(predictions, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
