{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scenes_gpu_torch(video_path, threshold=0.5, resolution=(256, 256)):\n",
    "    \"\"\"\n",
    "    Extract scene-based keyframes using PyTorch and GPU acceleration with improved GPU utilization\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Read video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Pre-load a larger number of frames to CPU memory first\n",
    "    preload_batch = 32  # Increased from 8\n",
    "    all_frames = []\n",
    "    all_indices = []\n",
    "    \n",
    "    # Read frames into CPU memory\n",
    "    for frame_idx in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Resize and normalize on CPU\n",
    "        frame = cv2.resize(frame, resolution)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        all_frames.append(frame)\n",
    "        all_indices.append(frame_idx)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Now process on GPU in larger batches\n",
    "    keyframes = []\n",
    "    frame_indices = []\n",
    "    prev_frame_tensor = None\n",
    "    \n",
    "    # Process in larger GPU batches\n",
    "    batch_size = 64  # Significantly increased batch size\n",
    "    \n",
    "    for i in range(0, len(all_frames), batch_size):\n",
    "        batch_frames = all_frames[i:i+batch_size]\n",
    "        batch_indices = all_indices[i:i+batch_size]\n",
    "        \n",
    "        # Convert batch to tensor - this will be a larger tensor now\n",
    "        batch_tensor = torch.tensor(np.array(batch_frames), \n",
    "                                  dtype=torch.float32, \n",
    "                                  device=device) / 255.0\n",
    "        \n",
    "        # Force GPU synchronization to ensure utilization is measured\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # First frame is always a keyframe\n",
    "        if prev_frame_tensor is None:\n",
    "            keyframes.append(batch_frames[0])\n",
    "            frame_indices.append(batch_indices[0])\n",
    "            prev_frame_tensor = batch_tensor[0].unsqueeze(0)\n",
    "            continue\n",
    "        \n",
    "        # Add some more intensive operations to better utilize GPU\n",
    "        # Calculate differences between all frames in batch and previous frame\n",
    "        expanded_prev = prev_frame_tensor.expand(len(batch_frames), -1, -1, -1)\n",
    "        \n",
    "        # This operation should be more intensive for the GPU\n",
    "        diffs = torch.norm(batch_tensor - expanded_prev, dim=(1,2,3))\n",
    "        \n",
    "        # Force synchronization again\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Process results\n",
    "        for j in range(len(batch_frames)):\n",
    "            if diffs[j].item() > threshold:\n",
    "                keyframes.append(batch_frames[j])\n",
    "                frame_indices.append(batch_indices[j])\n",
    "            \n",
    "        # Update previous frame\n",
    "        prev_frame_tensor = batch_tensor[-1].unsqueeze(0)\n",
    "    \n",
    "    return keyframes, frame_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "linalg.matrix_norm: dim must be a 2-tuple. Got 1 2 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_scenes_gpu_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE:/Multimedia/0/1430100-main-compressed.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 62\u001b[0m, in \u001b[0;36mextract_scenes_gpu_torch\u001b[1;34m(video_path, threshold, resolution)\u001b[0m\n\u001b[0;32m     59\u001b[0m expanded_prev \u001b[38;5;241m=\u001b[39m prev_frame_tensor\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;28mlen\u001b[39m(batch_frames), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# This operation should be more intensive for the GPU\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m diffs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexpanded_prev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Force synchronization again\u001b[39;00m\n\u001b[0;32m     65\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[1;32mc:\\Users\\Hieu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\functional.py:1818\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m   1816\u001b[0m     _dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim))\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1818\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatrix_norm(\n\u001b[0;32m   1821\u001b[0m         \u001b[38;5;28minput\u001b[39m, p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout\n\u001b[0;32m   1822\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: linalg.matrix_norm: dim must be a 2-tuple. Got 1 2 3"
     ]
    }
   ],
   "source": [
    "extract_scenes_gpu_torch('E:/Multimedia/0/1430100-main-compressed.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "PyTorch CUDA version: 12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"PyTorch CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
