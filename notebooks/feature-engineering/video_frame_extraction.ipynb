{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:25:41.583989Z",
     "start_time": "2025-04-12T13:25:41.572683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scenedetect import detect, AdaptiveDetector, ContentDetector, ThresholdDetector\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import json"
   ],
   "id": "4aa577d670aed1d3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:25:41.601896Z",
     "start_time": "2025-04-12T13:25:41.593726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_solid_color(frame, threshold=0.98, color_variance_threshold=100):\n",
    "    \"\"\"\n",
    "    Detects if a frame is mostly a solid color (includes black/white/any uniform color).\n",
    "\n",
    "    Args:\n",
    "        frame: Input frame (BGR format)\n",
    "        threshold: Percentage of the frame that must be similar color (0.0-1.0)\n",
    "        color_variance_threshold: Maximum variance in each channel to consider colors similar\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the frame is mostly solid color, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if the frame is empty or invalid\n",
    "    if frame is None or frame.size == 0:\n",
    "        return True\n",
    "\n",
    "    # Convert to all three channels if grayscale\n",
    "    if len(frame.shape) == 2:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Split the image into channels\n",
    "    channels = cv2.split(frame)\n",
    "    h, w = frame.shape[:2]\n",
    "    total_pixels = h * w\n",
    "\n",
    "    # Check each channel for variance\n",
    "    is_uniform = True\n",
    "    for channel in channels:\n",
    "        # Calculate variance for the channel\n",
    "        channel_variance = np.var(channel)\n",
    "\n",
    "        # If variance is high, the image is not uniform in this channel\n",
    "        if channel_variance > color_variance_threshold:\n",
    "            is_uniform = False\n",
    "            break\n",
    "\n",
    "    # If initial variance check suggests uniformity, do pixel-wise analysis\n",
    "    if is_uniform:\n",
    "        # Get dominant color (center color as approximation for speed)\n",
    "        center_y, center_x = h // 2, w // 2\n",
    "        dominant_color = frame[center_y, center_x].copy()\n",
    "\n",
    "        # Define acceptable range around dominant color\n",
    "        lower_bound = dominant_color - np.array([20, 20, 20])\n",
    "        upper_bound = dominant_color + np.array([20, 20, 20])\n",
    "\n",
    "        # Create mask of pixels that match the dominant color range\n",
    "        mask = cv2.inRange(frame, lower_bound, upper_bound)\n",
    "\n",
    "        # Calculate percentage of frame that matches dominant color\n",
    "        matching_pixels = cv2.countNonZero(mask)\n",
    "        percentage = matching_pixels / total_pixels\n",
    "\n",
    "        return percentage >= threshold\n",
    "\n",
    "    return False\n",
    "\n",
    "def is_blurry(frame, threshold=150, roi_crop=None):\n",
    "    \"\"\"\n",
    "    Detects if a frame is blurry using Laplacian variance.\n",
    "\n",
    "    Args:\n",
    "        frame: Input frame (BGR format)\n",
    "        threshold: Blur threshold - lower values mean more sensitive to blur\n",
    "                   Typical values: 100-150 for 720p/1080p images\n",
    "        roi_crop: Optional tuple (top_percent, bottom_percent, left_percent, right_percent)\n",
    "                  to crop the frame and analyze only the central region\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the frame is blurry, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if the frame is empty or invalid\n",
    "    if frame is None or frame.size == 0:\n",
    "        return True\n",
    "\n",
    "    # Make a copy to avoid modifying the original\n",
    "    working_frame = frame.copy()\n",
    "\n",
    "    # Apply optional ROI cropping to focus on the central part of the image\n",
    "    if roi_crop is not None:\n",
    "        top, bottom, left, right = roi_crop\n",
    "        h, w = working_frame.shape[:2]\n",
    "\n",
    "        # Calculate crop coordinates\n",
    "        top_px = int(h * top / 100)\n",
    "        bottom_px = int(h * (100 - bottom) / 100)\n",
    "        left_px = int(w * left / 100)\n",
    "        right_px = int(w * (100 - right) / 100)\n",
    "\n",
    "        # Ensure valid crop region\n",
    "        if bottom_px > top_px and right_px > left_px:\n",
    "            working_frame = working_frame[top_px:bottom_px, left_px:right_px]\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(working_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Skip very dark or very bright frames as they can give false positives\n",
    "    brightness = np.mean(gray)\n",
    "    if brightness < 20 or brightness > 235:\n",
    "        return False  # Exclude very dark/bright frames from blur detection\n",
    "\n",
    "    # Calculate the Laplacian\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "\n",
    "    # Calculate the variance (a measure of \"sharpness\")\n",
    "    score = laplacian.var()\n",
    "\n",
    "    # Normalize the score based on image size for better threshold consistency\n",
    "    # The adjustment helps make the threshold more stable across different resolutions\n",
    "    h, w = gray.shape\n",
    "    normalized_score = score * (1920 * 1080) / (h * w)\n",
    "\n",
    "    return normalized_score < threshold\n",
    "\n",
    "def is_overexposed(frame, highlight_threshold=230, overexposed_percentage=0.5):\n",
    "    \"\"\"\n",
    "    Detects if a frame is overexposed (too many bright/blown-out highlights).\n",
    "\n",
    "    Args:\n",
    "        frame: Input frame (BGR format)\n",
    "        highlight_threshold: Pixel value threshold for considering a pixel \"blown out\" (0-255)\n",
    "        overexposed_percentage: What percentage of the frame needs to be overexposed\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the frame is overexposed, False otherwise\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Count pixels that are very bright (blown out highlights)\n",
    "    num_highlight_pixels = np.sum(gray > highlight_threshold)\n",
    "\n",
    "    # Calculate the percentage of the frame that is blown out\n",
    "    total_pixels = gray.size\n",
    "    highlight_percentage = num_highlight_pixels / total_pixels\n",
    "\n",
    "    # Check if the percentage exceeds the threshold\n",
    "    return highlight_percentage > overexposed_percentage"
   ],
   "id": "c3452f8dc5dce1f3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:25:41.608485Z",
     "start_time": "2025-04-12T13:25:41.602861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_video_information(video_path):\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    cap.release()\n",
    "    return video_name, fps, duration"
   ],
   "id": "6b7aaa1caa4bf256",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:25:41.616605Z",
     "start_time": "2025-04-12T13:25:41.613176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_frames(video_name, output_dir, frame, frame_count):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    video_dir = os.path.join(output_dir, video_name)\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    frame_path = os.path.join(video_dir, f\"{frame_count}.jpg\")\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "    return frame_path"
   ],
   "id": "3d423fea462f4030",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:25:41.628662Z",
     "start_time": "2025-04-12T13:25:41.621932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_middle_frames(video_path, output_dir, verbose=True):\n",
    "\n",
    "    video_name, fps, duration = get_video_information(video_path)\n",
    "    min_num_scenes = 16\n",
    "\n",
    "    threshold = 15.0\n",
    "    min_threshold = 1.0\n",
    "    detector = ContentDetector(threshold=threshold)\n",
    "    scene_list = detect(video_path, detector)\n",
    "    print(f\"Detected {len(scene_list)} scenes in {video_path}\") if verbose else None\n",
    "\n",
    "    if len(scene_list) < min_num_scenes:\n",
    "        threshold = threshold * len(scene_list) / min_num_scenes\n",
    "        threshold = max(threshold, min_threshold)\n",
    "        print(f\"Decreasing content threshold to {threshold}\") if verbose else None\n",
    "        detector = ContentDetector(threshold=threshold)\n",
    "        scene_list = detect(video_path, detector)\n",
    "        print(f\"Detected {len(scene_list)} scenes in {video_path}\") if verbose else None\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_paths = []\n",
    "\n",
    "    # Extract middle frame from each scene\n",
    "    for scene in scene_list:\n",
    "        start_frame, end_frame = scene[0].frame_num, scene[1].frame_num\n",
    "        scene_length = end_frame - start_frame\n",
    "\n",
    "        # Calculate middle frame position\n",
    "        middle_frame = start_frame + scene_length // 2\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        if is_solid_color(frame) or is_blurry(frame) or is_overexposed(frame):\n",
    "            continue\n",
    "\n",
    "        frame_path = save_frames(video_name, output_dir, frame, len(frame_paths)+1)\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    cap.release()\n",
    "    return frame_paths"
   ],
   "id": "144647654d091865",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:25:41.638801Z",
     "start_time": "2025-04-12T13:25:41.633936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_all_files():\n",
    "    video_dir = 'E:/queue'\n",
    "    files = glob.glob(os.path.join(video_dir, '*.mp4'))\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "def update_progress(prog):\n",
    "    with open('frame-extraction-progress.json', 'w') as file:\n",
    "        json.dump(prog, file)\n",
    "\n",
    "def get_progress():\n",
    "    if not os.path.exists('frame-extraction-progress.json'):\n",
    "        return []\n",
    "    with open('frame-extraction-progress.json', 'r') as file:\n",
    "        prog = json.load(file)\n",
    "    return prog\n",
    "\n",
    "def get_item_ids():\n",
    "    with open('../../data/item_ids.json', 'r') as file:\n",
    "        item_ids = json.load(file)\n",
    "    return item_ids"
   ],
   "id": "1746e09bc0e6ff97",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:25:42.188897Z",
     "start_time": "2025-04-12T13:25:41.642994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_files = get_all_files()\n",
    "progress = get_progress()\n",
    "item_ids = get_item_ids()\n",
    "remain_files = []\n",
    "for file in all_files:\n",
    "    not_processed = file not in progress\n",
    "    in_metadata = int(os.path.splitext(os.path.basename(file))[0]) in item_ids\n",
    "    if not_processed and in_metadata:\n",
    "        remain_files.append(file)\n",
    "    else:\n",
    "        print(f\"Skipping {file}\")"
   ],
   "id": "1949542c2afcfa95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping E:/queue\\1217530.mp4\n",
      "Skipping E:/queue\\1217710.mp4\n",
      "Skipping E:/queue\\1217990.mp4\n",
      "Skipping E:/queue\\1218130.mp4\n",
      "Skipping E:/queue\\1218150.mp4\n",
      "Skipping E:/queue\\1218220.mp4\n",
      "Skipping E:/queue\\1218400.mp4\n",
      "Skipping E:/queue\\1218510.mp4\n",
      "Skipping E:/queue\\1218780.mp4\n",
      "Skipping E:/queue\\1219000.mp4\n",
      "Skipping E:/queue\\1219140.mp4\n",
      "Skipping E:/queue\\1219340.mp4\n",
      "Skipping E:/queue\\1219530.mp4\n",
      "Skipping E:/queue\\1219550.mp4\n",
      "Skipping E:/queue\\1219690.mp4\n",
      "Skipping E:/queue\\1219810.mp4\n",
      "Skipping E:/queue\\1220300.mp4\n",
      "Skipping E:/queue\\1220410.mp4\n",
      "Skipping E:/queue\\1220550.mp4\n",
      "Skipping E:/queue\\1220560.mp4\n",
      "Skipping E:/queue\\1220760.mp4\n",
      "Skipping E:/queue\\1221310.mp4\n",
      "Skipping E:/queue\\1221950.mp4\n",
      "Skipping E:/queue\\1221980.mp4\n",
      "Skipping E:/queue\\1222290.mp4\n",
      "Skipping E:/queue\\1222330.mp4\n",
      "Skipping E:/queue\\1222550.mp4\n",
      "Skipping E:/queue\\1222560.mp4\n",
      "Skipping E:/queue\\1222960.mp4\n",
      "Skipping E:/queue\\1223140.mp4\n",
      "Skipping E:/queue\\1223180.mp4\n",
      "Skipping E:/queue\\1223220.mp4\n",
      "Skipping E:/queue\\1223360.mp4\n",
      "Skipping E:/queue\\1224070.mp4\n",
      "Skipping E:/queue\\1224220.mp4\n",
      "Skipping E:/queue\\1225410.mp4\n",
      "Skipping E:/queue\\1225690.mp4\n",
      "Skipping E:/queue\\1225880.mp4\n",
      "Skipping E:/queue\\1226150.mp4\n",
      "Skipping E:/queue\\1226190.mp4\n",
      "Skipping E:/queue\\1226550.mp4\n",
      "Skipping E:/queue\\1226560.mp4\n",
      "Skipping E:/queue\\1226580.mp4\n",
      "Skipping E:/queue\\1227070.mp4\n",
      "Skipping E:/queue\\1228390.mp4\n",
      "Skipping E:/queue\\1228460.mp4\n",
      "Skipping E:/queue\\1228510.mp4\n",
      "Skipping E:/queue\\1228760.mp4\n",
      "Skipping E:/queue\\1230360.mp4\n",
      "Skipping E:/queue\\1230490.mp4\n",
      "Skipping E:/queue\\1231070.mp4\n",
      "Skipping E:/queue\\1231210.mp4\n",
      "Skipping E:/queue\\1232210.mp4\n",
      "Skipping E:/queue\\1232470.mp4\n",
      "Skipping E:/queue\\1232800.mp4\n",
      "Skipping E:/queue\\1233300.mp4\n",
      "Skipping E:/queue\\1233680.mp4\n",
      "Skipping E:/queue\\1233740.mp4\n",
      "Skipping E:/queue\\1234410.mp4\n",
      "Skipping E:/queue\\1234680.mp4\n",
      "Skipping E:/queue\\1234870.mp4\n",
      "Skipping E:/queue\\1234880.mp4\n",
      "Skipping E:/queue\\1234920.mp4\n",
      "Skipping E:/queue\\1234970.mp4\n",
      "Skipping E:/queue\\1234990.mp4\n",
      "Skipping E:/queue\\1235340.mp4\n",
      "Skipping E:/queue\\1235470.mp4\n",
      "Skipping E:/queue\\1235710.mp4\n",
      "Skipping E:/queue\\1236170.mp4\n",
      "Skipping E:/queue\\1236630.mp4\n",
      "Skipping E:/queue\\1236800.mp4\n",
      "Skipping E:/queue\\1237190.mp4\n",
      "Skipping E:/queue\\1237250.mp4\n",
      "Skipping E:/queue\\1237660.mp4\n",
      "Skipping E:/queue\\1238190.mp4\n",
      "Skipping E:/queue\\1238390.mp4\n",
      "Skipping E:/queue\\1238650.mp4\n",
      "Skipping E:/queue\\1238780.mp4\n",
      "Skipping E:/queue\\1238940.mp4\n",
      "Skipping E:/queue\\1239280.mp4\n",
      "Skipping E:/queue\\1239360.mp4\n",
      "Skipping E:/queue\\1239600.mp4\n",
      "Skipping E:/queue\\1239930.mp4\n",
      "Skipping E:/queue\\1240160.mp4\n",
      "Skipping E:/queue\\1241390.mp4\n",
      "Skipping E:/queue\\1241540.mp4\n",
      "Skipping E:/queue\\1241630.mp4\n",
      "Skipping E:/queue\\1241740.mp4\n",
      "Skipping E:/queue\\1243050.mp4\n",
      "Skipping E:/queue\\1243550.mp4\n",
      "Skipping E:/queue\\1244040.mp4\n",
      "Skipping E:/queue\\1244150.mp4\n",
      "Skipping E:/queue\\1244390.mp4\n",
      "Skipping E:/queue\\1244410.mp4\n",
      "Skipping E:/queue\\1244600.mp4\n",
      "Skipping E:/queue\\1244610.mp4\n",
      "Skipping E:/queue\\1244620.mp4\n",
      "Skipping E:/queue\\1245140.mp4\n",
      "Skipping E:/queue\\1245220.mp4\n",
      "Skipping E:/queue\\1245440.mp4\n",
      "Skipping E:/queue\\1246040.mp4\n",
      "Skipping E:/queue\\1247470.mp4\n",
      "Skipping E:/queue\\1248200.mp4\n",
      "Skipping E:/queue\\1248230.mp4\n",
      "Skipping E:/queue\\1248540.mp4\n",
      "Skipping E:/queue\\1249270.mp4\n",
      "Skipping E:/queue\\1249670.mp4\n",
      "Skipping E:/queue\\1249820.mp4\n",
      "Skipping E:/queue\\1250160.mp4\n",
      "Skipping E:/queue\\1250670.mp4\n",
      "Skipping E:/queue\\1250850.mp4\n",
      "Skipping E:/queue\\1250860.mp4\n",
      "Skipping E:/queue\\1251240.mp4\n",
      "Skipping E:/queue\\1251310.mp4\n",
      "Skipping E:/queue\\1251530.mp4\n",
      "Skipping E:/queue\\1251580.mp4\n",
      "Skipping E:/queue\\1251670.mp4\n",
      "Skipping E:/queue\\1251780.mp4\n",
      "Skipping E:/queue\\1251800.mp4\n",
      "Skipping E:/queue\\1251960.mp4\n",
      "Skipping E:/queue\\1252010.mp4\n",
      "Skipping E:/queue\\1252070.mp4\n",
      "Skipping E:/queue\\1252130.mp4\n",
      "Skipping E:/queue\\1252370.mp4\n",
      "Skipping E:/queue\\1252380.mp4\n",
      "Skipping E:/queue\\1252720.mp4\n",
      "Skipping E:/queue\\1253550.mp4\n",
      "Skipping E:/queue\\1253730.mp4\n",
      "Skipping E:/queue\\1253800.mp4\n",
      "Skipping E:/queue\\1254740.mp4\n",
      "Skipping E:/queue\\1255720.mp4\n",
      "Skipping E:/queue\\1255800.mp4\n",
      "Skipping E:/queue\\1255820.mp4\n",
      "Skipping E:/queue\\1255890.mp4\n",
      "Skipping E:/queue\\1256270.mp4\n",
      "Skipping E:/queue\\1256330.mp4\n",
      "Skipping E:/queue\\1256400.mp4\n",
      "Skipping E:/queue\\1256730.mp4\n",
      "Skipping E:/queue\\1256900.mp4\n",
      "Skipping E:/queue\\1256970.mp4\n",
      "Skipping E:/queue\\1257370.mp4\n",
      "Skipping E:/queue\\1257480.mp4\n",
      "Skipping E:/queue\\1257710.mp4\n",
      "Skipping E:/queue\\1258230.mp4\n",
      "Skipping E:/queue\\1258820.mp4\n",
      "Skipping E:/queue\\1259150.mp4\n",
      "Skipping E:/queue\\1259910.mp4\n",
      "Skipping E:/queue\\1259950.mp4\n",
      "Skipping E:/queue\\1260310.mp4\n",
      "Skipping E:/queue\\1260330.mp4\n",
      "Skipping E:/queue\\1260430.mp4\n",
      "Skipping E:/queue\\1260450.mp4\n",
      "Skipping E:/queue\\1260740.mp4\n",
      "Skipping E:/queue\\1260780.mp4\n",
      "Skipping E:/queue\\1261060.mp4\n",
      "Skipping E:/queue\\1314190.mp4\n",
      "Skipping E:/queue\\1314970.mp4\n",
      "Skipping E:/queue\\1315000.mp4\n",
      "Skipping E:/queue\\1315130.mp4\n",
      "Skipping E:/queue\\1315780.mp4\n",
      "Skipping E:/queue\\1315840.mp4\n",
      "Skipping E:/queue\\1316100.mp4\n",
      "Skipping E:/queue\\1316220.mp4\n",
      "Skipping E:/queue\\1316440.mp4\n",
      "Skipping E:/queue\\1317360.mp4\n",
      "Skipping E:/queue\\1318020.mp4\n",
      "Skipping E:/queue\\1318060.mp4\n",
      "Skipping E:/queue\\1318170.mp4\n",
      "Skipping E:/queue\\1318180.mp4\n",
      "Skipping E:/queue\\1318190.mp4\n",
      "Skipping E:/queue\\1318260.mp4\n",
      "Skipping E:/queue\\1318450.mp4\n",
      "Skipping E:/queue\\1318990.mp4\n",
      "Skipping E:/queue\\1319310.mp4\n",
      "Skipping E:/queue\\1319480.mp4\n",
      "Skipping E:/queue\\1319530.mp4\n",
      "Skipping E:/queue\\1319950.mp4\n",
      "Skipping E:/queue\\1319990.mp4\n",
      "Skipping E:/queue\\1320060.mp4\n",
      "Skipping E:/queue\\1320170.mp4\n",
      "Skipping E:/queue\\1320430.mp4\n",
      "Skipping E:/queue\\1320810.mp4\n",
      "Skipping E:/queue\\1321160.mp4\n",
      "Skipping E:/queue\\1321630.mp4\n",
      "Skipping E:/queue\\1321870.mp4\n",
      "Skipping E:/queue\\1323140.mp4\n",
      "Skipping E:/queue\\1323370.mp4\n",
      "Skipping E:/queue\\1323710.mp4\n",
      "Skipping E:/queue\\1323930.mp4\n",
      "Skipping E:/queue\\1324400.mp4\n",
      "Skipping E:/queue\\1324510.mp4\n",
      "Skipping E:/queue\\1324540.mp4\n",
      "Skipping E:/queue\\1324720.mp4\n",
      "Skipping E:/queue\\1324760.mp4\n",
      "Skipping E:/queue\\1324840.mp4\n",
      "Skipping E:/queue\\1324980.mp4\n",
      "Skipping E:/queue\\1325230.mp4\n",
      "Skipping E:/queue\\1325400.mp4\n",
      "Skipping E:/queue\\1326080.mp4\n",
      "Skipping E:/queue\\1326710.mp4\n",
      "Skipping E:/queue\\1326930.mp4\n",
      "Skipping E:/queue\\1327030.mp4\n",
      "Skipping E:/queue\\1327090.mp4\n",
      "Skipping E:/queue\\1327140.mp4\n",
      "Skipping E:/queue\\1327200.mp4\n",
      "Skipping E:/queue\\1327310.mp4\n",
      "Skipping E:/queue\\1328540.mp4\n",
      "Skipping E:/queue\\1328720.mp4\n",
      "Skipping E:/queue\\1328870.mp4\n",
      "Skipping E:/queue\\1329180.mp4\n",
      "Skipping E:/queue\\1329210.mp4\n",
      "Skipping E:/queue\\1329250.mp4\n",
      "Skipping E:/queue\\1329280.mp4\n",
      "Skipping E:/queue\\1329390.mp4\n",
      "Skipping E:/queue\\1330270.mp4\n",
      "Skipping E:/queue\\1330400.mp4\n",
      "Skipping E:/queue\\1330430.mp4\n",
      "Skipping E:/queue\\1330620.mp4\n",
      "Skipping E:/queue\\1331170.mp4\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-12T13:25:42.195242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, file in enumerate(remain_files):\n",
    "    print(f\"Processing {i+1}/{len(remain_files)}: {file}\")\n",
    "    frames = extract_middle_frames(file, 'D:/frames')\n",
    "    progress.append(file)\n",
    "    update_progress(progress)"
   ],
   "id": "b27b1d5934dd6f65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/1781: E:/queue\\10090.mp4\n",
      "Detected 38 scenes in E:/queue\\10090.mp4\n",
      "Processing 2/1781: E:/queue\\102600.mp4\n",
      "Detected 26 scenes in E:/queue\\102600.mp4\n",
      "Processing 3/1781: E:/queue\\102840.mp4\n",
      "Detected 34 scenes in E:/queue\\102840.mp4\n",
      "Processing 4/1781: E:/queue\\104000.mp4\n",
      "Detected 2 scenes in E:/queue\\104000.mp4\n",
      "Decreasing content threshold to 1.875\n",
      "Detected 16 scenes in E:/queue\\104000.mp4\n",
      "Processing 5/1781: E:/queue\\104020.mp4\n",
      "Detected 14 scenes in E:/queue\\104020.mp4\n",
      "Decreasing content threshold to 13.125\n",
      "Detected 14 scenes in E:/queue\\104020.mp4\n",
      "Processing 6/1781: E:/queue\\104900.mp4\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
