{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:34:00.467031Z",
     "start_time": "2025-04-11T23:34:00.459699Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import NCFDataset\n",
    "from recom_ncf import NCFRecommender\n",
    "from evaluation import Evaluation\n",
    "from helpers.index_manager import IndexManager\n",
    "from helpers.splitter import Splitter\n",
    "from helpers.dataloader_custom_functions import collate_fn"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:34:05.373627Z",
     "start_time": "2025-04-11T23:34:00.475602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/interaction-clean.csv')[['user_id', 'item_id', 'rating_imp', 'timestamp']]\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             user_id  item_id  rating_imp   timestamp\n",
       "0  76561197960432447       10           1  1738278781\n",
       "1  76561198071230926       10           1  1736206418\n",
       "2  76561198206216352       10           1  1738041574\n",
       "3  76561198110801124       10           1  1738015332\n",
       "4  76561199813732773       10           1  1737853720"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating_imp</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960432447</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1738278781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561198071230926</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1736206418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198206216352</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1738041574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198110801124</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1738015332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561199813732773</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1737853720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Indexing data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:34:09.148352Z",
     "start_time": "2025-04-11T23:34:05.406397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index_manager = IndexManager()\n",
    "index_manager.fit(df_interaction=df)\n",
    "index_manager.transform_interactions(df, inplace=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 836887 users and 69001 items\n",
      "User index range: 0-836886\n",
      "Item index range: 0-69000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         user_id  item_id  rating_imp   timestamp\n",
       "0              0        0           1  1738278781\n",
       "1              1        0           1  1736206418\n",
       "2              2        0           1  1738041574\n",
       "3              3        0           1  1738015332\n",
       "4              4        0           1  1737853720\n",
       "...          ...      ...         ...         ...\n",
       "1156221    15849    24891           1  1663545142\n",
       "1156222   150857    24891           1  1689826252\n",
       "1156223     1336    24892           1  1595699739\n",
       "1156224    11584    24892           0  1706470035\n",
       "1156225     2509    24892           1  1720163517\n",
       "\n",
       "[1156226 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating_imp</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1738278781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1736206418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1738041574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1738015332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1737853720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156221</th>\n",
       "      <td>15849</td>\n",
       "      <td>24891</td>\n",
       "      <td>1</td>\n",
       "      <td>1663545142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156222</th>\n",
       "      <td>150857</td>\n",
       "      <td>24891</td>\n",
       "      <td>1</td>\n",
       "      <td>1689826252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156223</th>\n",
       "      <td>1336</td>\n",
       "      <td>24892</td>\n",
       "      <td>1</td>\n",
       "      <td>1595699739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156224</th>\n",
       "      <td>11584</td>\n",
       "      <td>24892</td>\n",
       "      <td>0</td>\n",
       "      <td>1706470035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156225</th>\n",
       "      <td>2509</td>\n",
       "      <td>24892</td>\n",
       "      <td>1</td>\n",
       "      <td>1720163517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156226 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating datasets"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:34:53.852203Z",
     "start_time": "2025-04-11T23:34:09.169210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = Splitter(df)\n",
    "df_train, df_val, df_test = splitter.leave_k_out_split()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data with leave-2-out strategy (1 for validation, 1 for testing)\n",
      "Total users: 836887\n",
      "Interactions per user: min=1, max=1035, avg=1.4\n",
      "Note: 706515 users have fewer than 2 interactions.\n",
      "These users will be placed entirely in the training set.\n",
      "Split complete: 1156226 total interactions\n",
      "Train set: 895482 interactions (77.4%)\n",
      "Validation set: 130372 interactions (11.3%)\n",
      "Test set: 130372 interactions (11.3%)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:34:53.884590Z",
     "start_time": "2025-04-11T23:34:53.872541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = NCFDataset(df_train)\n",
    "val_dataset = NCFDataset(df_val)\n",
    "\n",
    "dataloader_params = {\n",
    "    'batch_size': 2**12,\n",
    "    # 'num_workers': 4,\n",
    "    # 'persistent_workers': True,\n",
    "    # 'prefetch_factor': 4,\n",
    "    'pin_memory': True,\n",
    "    'pin_memory_device': 'cuda',\n",
    "    'collate_fn': collate_fn,\n",
    "}\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, **dataloader_params)\n",
    "eval_dataloader = DataLoader(val_dataset, shuffle=False, **dataloader_params)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:36:07.422884Z",
     "start_time": "2025-04-11T23:34:53.912090Z"
    }
   },
   "source": [
    "params = {'factors': 8, 'mlp_user_item_dim': 128, 'learning_rate': 0.005, 'epochs': 5, 'optimizer': 'adagrad', 'dropout': 0.0, 'weight_decay': 0.0001, 'loss_fn': 'mse'}\n",
    "\n",
    "unique_users = index_manager.get_indexed_users()\n",
    "unique_items = index_manager.get_indexed_items()\n",
    "\n",
    "model = NCFRecommender(unique_users, unique_items, **params)\n",
    "model.fit(train_dataloader, eval_dataloader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train loss: 0.140880, Validation loss: 0.141613\n",
      "==================================================\n",
      "Epoch 2/5\n",
      "Train loss: 0.113580, Validation loss: 0.142883\n",
      "==================================================\n",
      "Epoch 3/5\n",
      "Train loss: 0.041731, Validation loss: 0.166845\n",
      "==================================================\n",
      "Epoch 4/5\n",
      "Train loss: 0.030197, Validation loss: 0.167814\n",
      "Early stopping triggered after 4 epochs\n",
      "Training completed!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:36:43.329009Z",
     "start_time": "2025-04-11T23:36:07.452348Z"
    }
   },
   "source": [
    "evaluator = Evaluation(recommender=model, test_data=df_test)\n",
    "metrics = evaluator.evaluate()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ground truth sets...\n",
      "Generating predictions...\n",
      "Processing 1 of 130372 users... (0.00%)\n",
      "Memory usage: 0.292724609375 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 128 to 141\n",
      "Increased item batch size from 1024 to 1126\n",
      "Processing 129 of 130372 users... (0.10%)\n",
      "Memory usage: 0.181884765625 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 141 to 155\n",
      "Increased item batch size from 1126 to 1239\n",
      "Processing 270 of 130372 users... (0.21%)\n",
      "Memory usage: 0.19677734375 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 155 to 170\n",
      "Increased item batch size from 1239 to 1363\n",
      "Processing 425 of 130372 users... (0.33%)\n",
      "Memory usage: 0.2119140625 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 170 to 187\n",
      "Increased item batch size from 1363 to 1499\n",
      "Processing 595 of 130372 users... (0.46%)\n",
      "Memory usage: 0.229736328125 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 187 to 206\n",
      "Increased item batch size from 1499 to 1649\n",
      "Processing 782 of 130372 users... (0.60%)\n",
      "Memory usage: 0.271728515625 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 206 to 227\n",
      "Increased item batch size from 1649 to 1814\n",
      "Processing 988 of 130372 users... (0.76%)\n",
      "Memory usage: 0.28076171875 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 227 to 250\n",
      "Increased item batch size from 1814 to 1995\n",
      "Processing 1215 of 130372 users... (0.93%)\n",
      "Memory usage: 0.312744140625 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 250 to 275\n",
      "Increased item batch size from 1995 to 2194\n",
      "Processing 1465 of 130372 users... (1.12%)\n",
      "Memory usage: 0.35302734375 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 275 to 302\n",
      "Increased item batch size from 2194 to 2413\n",
      "Processing 1740 of 130372 users... (1.33%)\n",
      "Memory usage: 0.44287109375 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 302 to 332\n",
      "Increased item batch size from 2413 to 2654\n",
      "Processing 2042 of 130372 users... (1.57%)\n",
      "Memory usage: 0.460205078125 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 332 to 365\n",
      "Increased item batch size from 2654 to 2919\n",
      "Processing 2374 of 130372 users... (1.82%)\n",
      "Memory usage: 0.529541015625 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 365 to 402\n",
      "Increased item batch size from 2919 to 3211\n",
      "Processing 2739 of 130372 users... (2.10%)\n",
      "Memory usage: 0.61279296875 . Increasing batch size with increasing rate of 1.1\n",
      "Increased user batch size from 402 to 442\n",
      "Increased item batch size from 3211 to 3532\n",
      "Processing 3141 of 130372 users... (2.41%)\n",
      "Processing 3583 of 130372 users... (2.75%)\n",
      "Processing 4025 of 130372 users... (3.09%)\n",
      "Processing 4467 of 130372 users... (3.43%)\n",
      "Processing 4909 of 130372 users... (3.76%)\n",
      "Processing 5351 of 130372 users... (4.10%)\n",
      "Processing 5793 of 130372 users... (4.44%)\n",
      "Processing 6235 of 130372 users... (4.78%)\n",
      "Processing 6677 of 130372 users... (5.12%)\n",
      "Processing 7119 of 130372 users... (5.46%)\n",
      "Processing 7561 of 130372 users... (5.80%)\n",
      "Processing 8003 of 130372 users... (6.14%)\n",
      "Processing 8445 of 130372 users... (6.48%)\n",
      "Processing 8887 of 130372 users... (6.82%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m evaluator \u001B[38;5;241m=\u001B[39m Evaluation(recommender\u001B[38;5;241m=\u001B[39mmodel, test_data\u001B[38;5;241m=\u001B[39mdf_test)\n\u001B[1;32m----> 2\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\multimodal-neural-collaborative-filtering\\evaluation.py:35\u001B[0m, in \u001B[0;36mEvaluation.evaluate\u001B[1;34m(self, k, user_batch_size, item_batch_size)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGenerating predictions...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     33\u001B[0m test_unique_users \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mground_truth\u001B[38;5;241m.\u001B[39mkeys()))\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecommender\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_predict_for_users\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43musers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_unique_users\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m    \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mitem_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mitem_batch_size\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m     43\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n",
      "File \u001B[1;32m~\\PycharmProjects\\multimodal-neural-collaborative-filtering\\recom_ncf.py:340\u001B[0m, in \u001B[0;36mNCFRecommender.batch_predict_for_users\u001B[1;34m(self, users, items, k, user_batch_size, item_batch_size)\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m all_scores\n\u001B[0;32m    339\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[1;32m--> 340\u001B[0m \u001B[43mgc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;66;03m# Move to next user batch\u001B[39;00m\n\u001B[0;32m    343\u001B[0m i \u001B[38;5;241m=\u001B[39m end_idx\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:36:43.337965100Z",
     "start_time": "2025-04-08T02:54:30.740443Z"
    }
   },
   "source": [
    "metrics"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hit Ratio@10': 0.011014635044334673,\n",
       " 'NDCG@10': 0.008220008934469699,\n",
       " 'Recall@10': 0.011014635044334673}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
